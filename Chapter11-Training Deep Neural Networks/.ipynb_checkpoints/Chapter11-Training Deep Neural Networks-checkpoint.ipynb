{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6c8ddc",
   "metadata": {},
   "source": [
    "# 梯度消失和梯度爆炸问题\n",
    "## Glorot和He初始化\n",
    "![Glorot](./Glorot.png)\n",
    "fanin是输入数量，fanout是神经元数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f33ec",
   "metadata": {},
   "source": [
    "| 初始化 | 激活函数                      | σ2(正常) |\n",
    "| ------ | ----------------------------- | --------- |\n",
    "| Glorot | None、tanh、logistic、softmax | 1/fan_avg |\n",
    "| He     | ReLU和变体                    | 2/fan_in  |\n",
    "| LeCun  | SELU                          |     1/fan_in      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9eeef4",
   "metadata": {},
   "source": [
    "默认情况下，keras使用均匀分布的Glorot初始化。创建层时，可以通过设置kernel_initializer='he_uniform'或者kernel_initializer='he_normal'来将其改为He初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b9ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.layers\n",
    "import keras.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53315fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x2e9a13fb508>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10,activation='relu',kernel_initializer='he_normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a27116",
   "metadata": {},
   "source": [
    "## 非饱和激活函数\n",
    "LeakyReLU<sub>a</sub>(z)=max(az,z)。超参数a定义函数泄露的程度：它是z<0时函数的斜率，通常设置成0.01。这个小的斜率确保了leaky ReLU永远不会死亡。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b2d04",
   "metadata": {},
   "source": [
    "指数线性单位ELU，该函数在作者的实验中胜过所有ReLU变体。![ELU](./ELU.png)\n",
    "- 当z<0时，它取负值。这使该单元的平均输出接近于0，有助于缓解梯度消失的问题。超参数a定义一个值，该值为当z为较大负数时ELU函数逼近的值，通常将其设置为1。\n",
    "- 当z<0时，它具有非0梯度，从而避免了神经元死亡的问题。\n",
    "- 如果a=1，则该函数在所有位置都是平滑的，这有助于加速梯度下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff86f000",
   "metadata": {},
   "source": [
    "要使用Leaky ReLU激活函数，创建一个Leaky ReLU层，并将其添加到你想用它的层之后。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c449a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=(1,1)))\n",
    "model.add(keras.layers.Dense(10,kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f65abf",
   "metadata": {},
   "source": [
    "要使用PReLU则改为keras.layers.PReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d2f95",
   "metadata": {},
   "source": [
    "对于SELU，在创建层时使用activation='selu'和kernel_initializer='lecun_normal'。SELU具体细节见书。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04be07e2",
   "metadata": {},
   "source": [
    "## 批量归一化\n",
    "该技术对每个输入零中心并归一化，然后每层使用两个新的参数向量缩放和偏移其结果：一个用于放缩，另一个用于偏移。换句话说，该操作可以使模型学习各层输入的最佳缩放和均值。详细见书。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c5c20",
   "metadata": {},
   "source": [
    "![BN](./BN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3bd3d",
   "metadata": {},
   "source": [
    "使用keras实现批量归一化，只需在每个隐藏层的激活函数之前或者之后添加一个BatchNormalization层，然后可选的在模型第一层之后添加一个BN层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc27261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(300,activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(100,activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa3c172c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb9c9e7",
   "metadata": {},
   "source": [
    "每个BN层添加了四个参数:γ、β、μ、σ。最后两个参数μ和σ是移动平均值。它们不受反向传播的影响。因此keras称其为不可训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75fef4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 让我们看一下第一个BN层的参数\n",
    "[(var.name,var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b70520",
   "metadata": {},
   "source": [
    "当你创建BN层时，它还会创建两个操作，在训练期间的每次迭代中，keras都会调用这两个操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec26d072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\envs\\ai\\lib\\site-packages\\keras\\engine\\base_layer.py:1307: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`layer.updates` will be removed in a future version. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7f45e",
   "metadata": {},
   "source": [
    "BN论文的作者主张在激活函数之前添加BN层(也可以之后，取决于任务)。此外，由于批量归一化层的每个输入都包含一个偏移参数，因此你可以从上一层中删除偏置项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42fe6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(300,kernel_initializer='he_normal',use_bias=False))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(100,kernel_initializer='he_normal',use_bias=False))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c29713a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               235200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 270,946\n",
      "Trainable params: 268,578\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8d3a5c",
   "metadata": {},
   "source": [
    "## 梯度裁剪\n",
    "为了防止梯度爆炸，在反向传播时裁剪梯度，使它永远不会超过某个阈值。称为梯度裁剪。这种技术通常用于循环神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0915b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.SGD(clipnorm=1.0)\n",
    "model.compile(loss='mse',optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332859ce",
   "metadata": {},
   "source": [
    "该优化器会将每个梯度向量的分量都裁剪为-1.0和1.0之间的数字。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0713573",
   "metadata": {},
   "source": [
    "# 重用预训练层\n",
    "## 用keras进行迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f68c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets.fashion_mnist import load_data\n",
    "(X_train_full, y_train_full), (X_test, y_test) =load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756216ea",
   "metadata": {},
   "source": [
    "让我们将时尚 MNIST 训练集一分为二：\n",
    "* `X_train_A`：除凉鞋和衬衫（第 5 类和第 6 类）之外的所有物品的所有图像。\n",
    "* `X_train_B`：一个小得多的训练集，只有前 200 张凉鞋或衬衫的图像。\n",
    "\n",
    "验证集和测试集也是这样拆分的，但是不限制图片的数量。\n",
    "\n",
    "我们将在集合 A（具有 8 个类别的分类任务）上训练一个模型，并尝试重用它来处理集合 B（二元分类）。 我们希望将一些知识从任务 A 转移到任务 B，因为集合 A 中的类（运动鞋、踝靴、外套、T 恤等）与集合 B 中的类（凉鞋和衬衫）有些相似。 然而，由于我们使用的是“密集”层，因此只有出现在同一位置的模式才能被重用（相比之下，卷积层会更好地转移，因为可以在图像的任何地方检测到学习到的模式，正如我们将在 CNN 章节）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3371171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "895e2ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2c51525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6130c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "423c4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33d6426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7de0acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 15s 2ms/step - loss: 0.9249 - accuracy: 0.6994 - val_loss: 0.3894 - val_accuracy: 0.8670\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3651 - accuracy: 0.8747 - val_loss: 0.3289 - val_accuracy: 0.8824\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3182 - accuracy: 0.8894 - val_loss: 0.3014 - val_accuracy: 0.8986\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3048 - accuracy: 0.8954 - val_loss: 0.2891 - val_accuracy: 0.9018\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2802 - accuracy: 0.9030 - val_loss: 0.2774 - val_accuracy: 0.9068\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2699 - accuracy: 0.9078 - val_loss: 0.2732 - val_accuracy: 0.9066\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2625 - accuracy: 0.9091 - val_loss: 0.2718 - val_accuracy: 0.9088\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2609 - accuracy: 0.9117 - val_loss: 0.2588 - val_accuracy: 0.9138\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2557 - accuracy: 0.9109 - val_loss: 0.2562 - val_accuracy: 0.9143\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2511 - accuracy: 0.9135 - val_loss: 0.2539 - val_accuracy: 0.9163\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2430 - accuracy: 0.9170 - val_loss: 0.2496 - val_accuracy: 0.9155\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2422 - accuracy: 0.9172 - val_loss: 0.2509 - val_accuracy: 0.9131\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2360 - accuracy: 0.9181 - val_loss: 0.2445 - val_accuracy: 0.9148\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2266 - accuracy: 0.9232 - val_loss: 0.2413 - val_accuracy: 0.9175\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2225 - accuracy: 0.9240 - val_loss: 0.2444 - val_accuracy: 0.9190\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2261 - accuracy: 0.9216 - val_loss: 0.2381 - val_accuracy: 0.9190\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2190 - accuracy: 0.9250 - val_loss: 0.2407 - val_accuracy: 0.9175\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2172 - accuracy: 0.9252 - val_loss: 0.2428 - val_accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2180 - accuracy: 0.9250 - val_loss: 0.2329 - val_accuracy: 0.9205\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2112 - accuracy: 0.9271 - val_loss: 0.2333 - val_accuracy: 0.9203\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4269fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10edb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fff3f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",optimizer=keras.optimizers.SGD(learning_rate=1e-3),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfa347c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 62ms/step - loss: 1.0360 - accuracy: 0.4975 - val_loss: 0.6314 - val_accuracy: 0.6004\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5883 - accuracy: 0.6971 - val_loss: 0.4784 - val_accuracy: 0.8529\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4380 - accuracy: 0.8854 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4021 - accuracy: 0.8712 - val_loss: 0.3647 - val_accuracy: 0.9178\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3361 - accuracy: 0.9348 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3113 - accuracy: 0.9233 - val_loss: 0.3019 - val_accuracy: 0.9402\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2817 - accuracy: 0.9299 - val_loss: 0.2804 - val_accuracy: 0.9422\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2632 - accuracy: 0.9379 - val_loss: 0.2606 - val_accuracy: 0.9473\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2373 - accuracy: 0.9481 - val_loss: 0.2428 - val_accuracy: 0.9523\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2229 - accuracy: 0.9657 - val_loss: 0.2281 - val_accuracy: 0.9544\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2155 - accuracy: 0.9590 - val_loss: 0.2150 - val_accuracy: 0.9584\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1834 - accuracy: 0.9738 - val_loss: 0.2036 - val_accuracy: 0.9584\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1671 - accuracy: 0.9828 - val_loss: 0.1931 - val_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1527 - accuracy: 0.9915 - val_loss: 0.1838 - val_accuracy: 0.9635\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1595 - accuracy: 0.9904 - val_loss: 0.1746 - val_accuracy: 0.9686\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1473 - accuracy: 0.9937 - val_loss: 0.1674 - val_accuracy: 0.9686\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1412 - accuracy: 0.9944 - val_loss: 0.1604 - val_accuracy: 0.9706\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1242 - accuracy: 0.9931 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1224 - accuracy: 0.9931 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1096 - accuracy: 0.9912 - val_loss: 0.1431 - val_accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25e07e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be107c04",
   "metadata": {},
   "source": [
    "首先你需要加载模型A并基于该模型的层创建一个新模型，让我们重用输出层以外的所有层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70194199",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A=keras.models.load_model(filepath='./my_model_A.h5')\n",
    "model_B_on_A=keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9b3903",
   "metadata": {},
   "source": [
    "目前，model_A和model_B_on_A共用一些层。当训练model_B_on_A时也会影响model_A。如果想避免这种情况应该先对model_A之前的层进行克隆。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04bcc2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone=keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34c432f",
   "metadata": {},
   "source": [
    "现在你可以训练model_B_on_A,但是由于新的输出层是随机初始化的，它会产生较大的错误，因此可能会产生较大的错误梯度，这可能会破坏重用的权重。可以在前几个训练轮次冻结重用的层，给新层一些时间来训练合理的权重。为此将每一层trainable设置为False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2e4e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable=False\n",
    "\n",
    "model_B_on_A.compile(loss='binary_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6543f6a",
   "metadata": {},
   "source": [
    "现在你可以训练几个轮次，然后解冻重用层(这需要再次编译),并继续进行训练。解冻重用层后降低学习率是个好主意，可以避免损坏重用层的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62f97781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 65ms/step - loss: 0.5403 - accuracy: 0.6783 - val_loss: 0.3602 - val_accuracy: 0.8448\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3016 - accuracy: 0.9225 - val_loss: 0.2369 - val_accuracy: 0.9422\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1812 - accuracy: 0.9777 - val_loss: 0.1784 - val_accuracy: 0.9645\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1455 - accuracy: 0.9858 - val_loss: 0.1454 - val_accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "history=model_B_on_A.fit(X_train_B,y_train_B,epochs=4,validation_data=(X_valid_B,y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7209de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bfb125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.SGD(learning_rate=1e-4)\n",
    "model_B_on_A.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05e2a161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 62ms/step - loss: 0.1211 - accuracy: 0.9912 - val_loss: 0.1435 - val_accuracy: 0.9838\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1159 - accuracy: 0.9912 - val_loss: 0.1416 - val_accuracy: 0.9828\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1074 - accuracy: 0.9931 - val_loss: 0.1396 - val_accuracy: 0.9828\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1150 - accuracy: 0.9894 - val_loss: 0.1379 - val_accuracy: 0.9828\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1027 - accuracy: 0.9944 - val_loss: 0.1361 - val_accuracy: 0.9828\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1042 - accuracy: 0.9937 - val_loss: 0.1344 - val_accuracy: 0.9838\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1136 - accuracy: 0.9823 - val_loss: 0.1329 - val_accuracy: 0.9848\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1116 - accuracy: 0.9881 - val_loss: 0.1314 - val_accuracy: 0.9848\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0996 - accuracy: 0.9879 - val_loss: 0.1296 - val_accuracy: 0.9838\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1020 - accuracy: 0.9946 - val_loss: 0.1283 - val_accuracy: 0.9838\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1000 - accuracy: 0.9873 - val_loss: 0.1269 - val_accuracy: 0.9848\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1111 - accuracy: 0.9892 - val_loss: 0.1255 - val_accuracy: 0.9848\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0938 - accuracy: 0.9981 - val_loss: 0.1241 - val_accuracy: 0.9848\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0914 - accuracy: 0.9963 - val_loss: 0.1229 - val_accuracy: 0.9848\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0996 - accuracy: 0.9892 - val_loss: 0.1217 - val_accuracy: 0.9848\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "history=model_B_on_A.fit(X_train_B,y_train_B,epochs=16,validation_data=(X_valid_B,y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "674f71b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11705686897039413, 0.987500011920929]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B,y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f0d876",
   "metadata": {},
   "source": [
    "## 无监督预训练\n",
    "见书。\n",
    "## 辅助任务的预训练\n",
    "见书。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d449b5d",
   "metadata": {},
   "source": [
    "# 更快的优化器\n",
    "## 动量优化\n",
    "![momentum](./momentum.png)\n",
    "动量优化非常关心先前的梯度是什么。梯度适用于加速度而不是速度。为了模拟某种摩擦机制为防止动量变得过大，该算法引入了一个新的超参数β，称为动量。必须将其设置为0(高摩擦)和1(低摩擦)之间。典型的动量值为0.9。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58c947a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.SGD(learning_rate=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b963758c",
   "metadata": {},
   "source": [
    "## Nesterov加速梯度\n",
    "Nesterov动量优化，它不是在局部位置θ，而是在θ+mβ处沿动量方向稍微提前处测量成本函数的梯度。\n",
    "![Nesterov](./Nesterov.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c6e8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.SGD(learning_rate=0.001,momentum=0.9,nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ebac87",
   "metadata": {},
   "source": [
    "## AdaGrad\n",
    "AdaGrad沿最陡峭的维度按比例缩小梯度向量来实现此校正。详细见书。\n",
    "![AdaGrad](./AdaGrad.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a708ae6",
   "metadata": {},
   "source": [
    "## RMSProp\n",
    "![RMSProp](./RMSProp.png)\n",
    "衰减率β通常设置成0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7da73bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.RMSprop(learning_rate=0.001,rho=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad465e",
   "metadata": {},
   "source": [
    "## Adam和Nadam优化\n",
    "![Adam](./Adam.png)\n",
    "动量衰减超参数β<sub>1</sub>设置为0.9,而缩放衰减超参数β<sub>2</sub>通常设置为0.999。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b007b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa8e84",
   "metadata": {},
   "source": [
    "## 优化器比较\n",
    "![optimizer comparison](./optimizer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fd956d",
   "metadata": {},
   "source": [
    "## 学习率调度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0f98e0",
   "metadata": {},
   "source": [
    "在keras上实现**幂调度**是最简单的。η(t)=η<sub>0</sub>/(1+t/s)^c.初始学习率η<sub>0</sub>,幂c和步骤s是超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01326fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.SGD(learning_rate=0.01,decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577635b",
   "metadata": {},
   "source": [
    "**指数调度**η(t)=η<sub>0</sub>*0.1<sup>t/s</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d418736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0,s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0*0.1**(epoch/s)\n",
    "    return exponential_decay_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212ecff",
   "metadata": {},
   "source": [
    "接下来创建一个LearningRateSchedule回调函数，为其提供调度函数，然后将此回调函数传递给fit()方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d8a6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3665df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler=keras.callbacks.LearningRateScheduler(exponential_decay_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd7b739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a650e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 1.0460 - accuracy: 0.7112 - val_loss: 1.0891 - val_accuracy: 0.6980\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5422 - accuracy: 0.8160 - val_loss: 0.4226 - val_accuracy: 0.8542\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4525 - accuracy: 0.8461 - val_loss: 0.5616 - val_accuracy: 0.8248\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4121 - accuracy: 0.8592 - val_loss: 0.4093 - val_accuracy: 0.8630\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3852 - accuracy: 0.8675 - val_loss: 0.3911 - val_accuracy: 0.8720\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3490 - accuracy: 0.8811 - val_loss: 0.3699 - val_accuracy: 0.8814\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3271 - accuracy: 0.8889 - val_loss: 0.3777 - val_accuracy: 0.8810\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3081 - accuracy: 0.8933 - val_loss: 0.3870 - val_accuracy: 0.8680\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3016 - accuracy: 0.8915 - val_loss: 0.3719 - val_accuracy: 0.8802\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2784 - accuracy: 0.9014 - val_loss: 0.3627 - val_accuracy: 0.8860\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2603 - accuracy: 0.9065 - val_loss: 0.3433 - val_accuracy: 0.8894\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2471 - accuracy: 0.9112 - val_loss: 0.3935 - val_accuracy: 0.8738\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2381 - accuracy: 0.9131 - val_loss: 0.3639 - val_accuracy: 0.8866\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2253 - accuracy: 0.9164 - val_loss: 0.3695 - val_accuracy: 0.8900\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2207 - accuracy: 0.9200 - val_loss: 0.3583 - val_accuracy: 0.8920\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2084 - accuracy: 0.9231 - val_loss: 0.3791 - val_accuracy: 0.8912\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1965 - accuracy: 0.9270 - val_loss: 0.3952 - val_accuracy: 0.8844\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1923 - accuracy: 0.9291 - val_loss: 0.3632 - val_accuracy: 0.8922\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1831 - accuracy: 0.9328 - val_loss: 0.3578 - val_accuracy: 0.8964\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1827 - accuracy: 0.9334 - val_loss: 0.3695 - val_accuracy: 0.8962\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1748 - accuracy: 0.9348 - val_loss: 0.3838 - val_accuracy: 0.8974\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1713 - accuracy: 0.9366 - val_loss: 0.3859 - val_accuracy: 0.8968\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1605 - accuracy: 0.9397 - val_loss: 0.3936 - val_accuracy: 0.8954\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1532 - accuracy: 0.9437 - val_loss: 0.3917 - val_accuracy: 0.8960\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1550 - accuracy: 0.9431 - val_loss: 0.4086 - val_accuracy: 0.8934\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11009e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1eb144",
   "metadata": {},
   "source": [
    "keras实现了另一种学习率调度的方法。使用keras.optimizers.schedule中可以使用的调度之一来定义学习率，然后再将学习率传递给优化器。这种方法在每个步骤更新学习率而不是每个周期。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e846966",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=20*len(X_train)//32  # 20个周期一共多少个batch\n",
    "learning_rate=keras.optimizers.schedules.ExponentialDecay(0.01,s,0.1)\n",
    "optimizer=keras.optimizers.SGD(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ab294",
   "metadata": {},
   "source": [
    "# 通过正则化避免过拟合\n",
    "## l1和l2正则化\n",
    "以下是使用0.01的正则化因子将l2正则化应用于Keras层的连接权重的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79146614",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer=keras.layers.Dense(100,activation='elu',kernel_initializer='he_normal',kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c77b0",
   "metadata": {},
   "source": [
    "如果你同时需要l1和l2正则化，则keras.regularizers.l1_l2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1bae97",
   "metadata": {},
   "source": [
    "由于你通常需要将相同的正则化函数应用于网络的所有层，并在隐藏层使用相同的激活函数和相同的初始化策略。所以可以使用python的functools.partial()函数，该函数可以使你为带有一些默认参数值得任何可调用对象穿件一个小小的包装函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9117a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "RegularizedDense = partial(keras.layers.Dense, activation='elu',\n",
    "                           kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02104568",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(RegularizedDense(300))\n",
    "model.add(RegularizedDense(100))\n",
    "model.add(RegularizedDense(10,activation='softmax',kernel_initializer='glorot_uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa0c14",
   "metadata": {},
   "source": [
    "## dropout\n",
    "详细见书。在实践中你通常只可以对第一层至第三层(不包括输出层)使用dropout。由于dropout仅在训练期间激活，因此比较训练损失和验证损失可能会产生误导。因此请确保没有使用dropout来评估训练损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb15b7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.7182 - accuracy: 0.7397 - val_loss: 0.4242 - val_accuracy: 0.8482\n",
      "Epoch 2/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4690 - accuracy: 0.8268 - val_loss: 0.3619 - val_accuracy: 0.8676\n",
      "Epoch 3/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4302 - accuracy: 0.8400 - val_loss: 0.3621 - val_accuracy: 0.8638\n",
      "Epoch 4/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4019 - accuracy: 0.8504 - val_loss: 0.3354 - val_accuracy: 0.8780\n",
      "Epoch 5/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3913 - accuracy: 0.8540 - val_loss: 0.3225 - val_accuracy: 0.8812\n",
      "Epoch 6/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3700 - accuracy: 0.8613 - val_loss: 0.3275 - val_accuracy: 0.8804\n",
      "Epoch 7/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3614 - accuracy: 0.8669 - val_loss: 0.3343 - val_accuracy: 0.8798\n",
      "Epoch 8/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3490 - accuracy: 0.8686 - val_loss: 0.3096 - val_accuracy: 0.8866\n",
      "Epoch 9/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3468 - accuracy: 0.8673 - val_loss: 0.3141 - val_accuracy: 0.8850\n",
      "Epoch 10/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3329 - accuracy: 0.8749 - val_loss: 0.3056 - val_accuracy: 0.8884\n",
      "Epoch 11/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3261 - accuracy: 0.8759 - val_loss: 0.2992 - val_accuracy: 0.8904\n",
      "Epoch 12/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3252 - accuracy: 0.8772 - val_loss: 0.3033 - val_accuracy: 0.8830\n",
      "Epoch 13/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3211 - accuracy: 0.8792 - val_loss: 0.3048 - val_accuracy: 0.8900\n",
      "Epoch 14/15\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3191 - accuracy: 0.8796 - val_loss: 0.3051 - val_accuracy: 0.8884\n",
      "Epoch 15/15\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3128 - accuracy: 0.8824 - val_loss: 0.3013 - val_accuracy: 0.8886\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train, y_train, epochs=15,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb27be",
   "metadata": {},
   "source": [
    "## 蒙特卡罗(MC)Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb3648e",
   "metadata": {},
   "source": [
    "## 最大范数正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d255a22",
   "metadata": {},
   "source": [
    "# 总结和实用指南"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c5f00",
   "metadata": {},
   "source": [
    "![DNN](./DNN.png)\n",
    "![DNN for a self-normalizing net](./DNN2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd3cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
