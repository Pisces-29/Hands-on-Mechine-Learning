{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7c496d",
   "metadata": {},
   "source": [
    "# 人工神经元\n",
    "## 感知器\n",
    "<img src=\"./perceptron.png\" style=\"zoom:40%\" />\n",
    "<img src=\"./perceptron2.png\" style=\"zoom:40%\" />\n",
    "\n",
    "- 当一层中的所有神经元都连接到上一层的每个神经元时，改层称为全连接层或者密集层。\n",
    "- 感知器的输入被送到称为输入神经元的特殊直通神经元，它们输出被送入的任何输入。\n",
    "- 所有输入神经元称为输入层。\n",
    "- 通常会添加一个额外的偏置特征(x<sub>0</sub>=1)：通常使用一种称为偏置神经元的特殊类型的神经元来表示该特征，该神经元始终输出1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f891c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ac2eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "X=iris.data[:,(2,3)]\n",
    "y=(iris.target==0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c0591ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_clf=Perceptron()\n",
    "per_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc0f7bd",
   "metadata": {},
   "source": [
    "## 多层感知器和反向传播\n",
    "- 正向传播和反向传播算法见书。\n",
    "- 注意以下几点：\n",
    "    - 随机初始化所有隐藏层的连接权重很重要，否则将训练失败。\n",
    "    - 将阶跃函数替换成激活函数。\n",
    "    - 如果没有阶跃函数，那么我们相当于连接多个线性变换，最终得到的只是一个线性变换。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc665a",
   "metadata": {},
   "source": [
    "## 回归MLP\n",
    "<img src=\"./MLPReg.png\" style=\"zoom:40%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ca7da6",
   "metadata": {},
   "source": [
    "## 分类MLP\n",
    "<img src=\"./MLPClf.png\" style=\"zoom:40%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0432431",
   "metadata": {},
   "source": [
    "## TensorFlow Playground\n",
    "http://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1f741",
   "metadata": {},
   "source": [
    "# 使用Keras实现MLP\n",
    "## 使用顺序API构建图像分类器\n",
    "### 使用keras加载数据集\n",
    "我们采用Fashion MNIST数据集。7000张图片，每幅28*28像素，有10个类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4531fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83db66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist=fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497e5d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full,y_train_full),(X_test,y_test)=fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b7948",
   "metadata": {},
   "source": [
    "使用keras加载MNIST或Fashion MNIST时，相较于sklearn的一个重要区别是每个图像都表示成28*28的阵列而不是784的一维阵列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4268ef45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa9a2f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4233a19",
   "metadata": {},
   "source": [
    "数据集已经分好了训练集和测试集，但是没有验证集。另外，我们要使用梯度下降法训练神经网络，因此必须等比例缩放特征。为简单起见，我们将像素强度除以255.0，将像素强度缩放到0-1范围内。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a8b6c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid,X_train=X_train_full[:5000]/255.0,X_train_full[5000:]/255.0\n",
    "y_valid,y_train=y_train_full[:5000],y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec743046",
   "metadata": {},
   "source": [
    "对于Fashion MNIST我们需要一个类别列表来知道我们要处理的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "958517d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2adb3eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例如\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6670cea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51143d2f",
   "metadata": {},
   "source": [
    "### 使用顺序api创建模型\n",
    "接下来我们用Sequential模型来构建神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d384b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1db47b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Flatten(input_shape=[28,28]))\n",
    "model.add(Dense(300,activation=\"relu\"))\n",
    "model.add(Dense(100,activation=\"relu\"))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c3a58",
   "metadata": {},
   "source": [
    "等同于书上如下代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d033c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3ec4f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300,activation='relu'))\n",
    "model.add(keras.layers.Dense(100,activation='relu'))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ff48e",
   "metadata": {},
   "source": [
    "还等同于如下代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1dbbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([keras.layers.Flatten(input_shape=[28, 28]), keras.layers.Dense(\n",
    "    300, activation='relu'), keras.layers.Dense(100, activation='relu'), keras.layers.Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b9e37",
   "metadata": {},
   "source": [
    "- 第一行是创建一个Sequential模型，它仅有顺序连接的单层堆栈组成。\n",
    "- Flatten层的作用是将每个输入图像转换成一维数组：如果接收到输入数据X，则执行X.reshape(-1,1)。所以该层只是做一些简单的预处理。由于是模型的第一层，应该指定input_shape。或者使用keras.layers.InputLayer作为第一层。\n",
    "- 接下来是具有300个神经元的隐藏层。它使用Relu作为激活函数。每个Dense管理自己的权重矩阵，其中包含神经元及其输入之间所有的连接权重。它还管理偏置项的一个向量。\n",
    "- 最后我们添加一个包含10个神经元的Dense输出层，使用softmax作为激活函数。\n",
    "- 指定activation=\"relu\"等效于activation=keras.activations.relu。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71aaf12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary()方法显示模型的所有层。\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a868aa",
   "metadata": {},
   "source": [
    "第一个隐藏层的连接权重为784*300，外加300个偏置项，总共235500个参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "862528b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Flatten at 0x1f97e663908>,\n",
       " <keras.layers.core.Dense at 0x1f97f2cfb88>,\n",
       " <keras.layers.core.Dense at 0x1f97f2cff48>,\n",
       " <keras.layers.core.Dense at 0x1f97f2cfe48>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以获取模型的层列表，按其索引获取层，也可以按名称获取。\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfa3cb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x1f97f2cfb88>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa379f4",
   "metadata": {},
   "source": [
    "还可以使用get_weights()和set_weights()方法访问层的所有参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab9f1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights,biases=model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4454674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c89e6c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12454284",
   "metadata": {},
   "source": [
    "注意，全连接层进行了随机初始化，并且偏置初始化为0，这是可以的。如果要使用其它初始化方法，则可以在创建层时设置kernel_initializer或bias_initializer。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4214f",
   "metadata": {},
   "source": [
    "权重矩阵的形状取决于输入的个数。这就是第一层指定input_shape的原因。如果不指定输入形状也是可以的：当你向模型提供数据时，keras才会真正的构建模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff5ef42",
   "metadata": {},
   "source": [
    "### 编译模型\n",
    "创建模型之后你必须使用compile()方法来指定损失函数和要使用的优化器。还可以选择指定在训练和评估期间要计算的其它指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18ebfd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14d21f",
   "metadata": {},
   "source": [
    "- 首先我们使用sparse_categorical_crossentropy损失，因为我们具有稀疏标签（对于每个实例只有一个目标类索引）。\n",
    "- 相反，如果每个实例的目标类都采用one-hot编码，则我们需要使用categorical_crossentropy损失。\n",
    "- 如果我们在执行二进制分类，则在输出层应该使用sigmoid激活函数，而不是softmax激活函数，并且使用binary_crossentropy。\n",
    "- 如果要将稀疏标签转换成one-hot编码，使用keras.utils.to_categorical()函数。反之使用np.argmax(axis=1)函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862d851",
   "metadata": {},
   "source": [
    "sgd表示我们使用简单的随机梯度下降来训练模型。使用SGD优化器时，调整学习率很重要。因此通常使用optimizer=keras.optimizers.SGD(lr=???)，而不是使用optimizer='sgd'(默认值lr=0.01)来设置学习率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b6264f",
   "metadata": {},
   "source": [
    "### 训练和评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0391304d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 18s 2ms/step - loss: 1.0015 - accuracy: 0.6831 - val_loss: 0.5273 - val_accuracy: 0.8142\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5066 - accuracy: 0.8233 - val_loss: 0.4452 - val_accuracy: 0.8494\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4501 - accuracy: 0.8426 - val_loss: 0.4136 - val_accuracy: 0.8568\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4159 - accuracy: 0.8550 - val_loss: 0.4045 - val_accuracy: 0.8626\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3960 - accuracy: 0.8607 - val_loss: 0.4202 - val_accuracy: 0.8502\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3814 - accuracy: 0.8639 - val_loss: 0.3784 - val_accuracy: 0.8726\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3709 - accuracy: 0.8671 - val_loss: 0.3664 - val_accuracy: 0.8762\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3486 - accuracy: 0.8744 - val_loss: 0.3549 - val_accuracy: 0.8786\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3403 - accuracy: 0.8777 - val_loss: 0.3534 - val_accuracy: 0.8752\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3328 - accuracy: 0.8816 - val_loss: 0.3474 - val_accuracy: 0.8812\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3296 - accuracy: 0.8812 - val_loss: 0.3436 - val_accuracy: 0.8786\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3171 - accuracy: 0.8866 - val_loss: 0.3332 - val_accuracy: 0.8836\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3125 - accuracy: 0.8877 - val_loss: 0.3340 - val_accuracy: 0.8800\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3034 - accuracy: 0.8900 - val_loss: 0.3468 - val_accuracy: 0.8790\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2938 - accuracy: 0.8951 - val_loss: 0.3541 - val_accuracy: 0.8748\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2922 - accuracy: 0.8948 - val_loss: 0.3512 - val_accuracy: 0.8770\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2848 - accuracy: 0.8976 - val_loss: 0.3285 - val_accuracy: 0.8846\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2815 - accuracy: 0.8997 - val_loss: 0.3212 - val_accuracy: 0.8866\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2741 - accuracy: 0.9009 - val_loss: 0.3159 - val_accuracy: 0.8908\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2685 - accuracy: 0.9042 - val_loss: 0.3254 - val_accuracy: 0.8824\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2642 - accuracy: 0.9048 - val_loss: 0.3051 - val_accuracy: 0.8914\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2588 - accuracy: 0.9063 - val_loss: 0.3130 - val_accuracy: 0.8840\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2503 - accuracy: 0.9088 - val_loss: 0.3015 - val_accuracy: 0.8902\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2459 - accuracy: 0.9098 - val_loss: 0.3189 - val_accuracy: 0.8834\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2441 - accuracy: 0.9125 - val_loss: 0.3134 - val_accuracy: 0.8906\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2422 - accuracy: 0.9134 - val_loss: 0.2993 - val_accuracy: 0.8970\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2343 - accuracy: 0.9150 - val_loss: 0.3354 - val_accuracy: 0.8860\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2328 - accuracy: 0.9160 - val_loss: 0.3061 - val_accuracy: 0.8910\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2276 - accuracy: 0.9172 - val_loss: 0.3111 - val_accuracy: 0.8916\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2253 - accuracy: 0.9179 - val_loss: 0.2964 - val_accuracy: 0.8914\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,epochs=30,validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654df99",
   "metadata": {},
   "source": [
    "可以将validation_split设置为用于验证的训练集比率，而不是使用validation_data参数传递验证集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2faada",
   "metadata": {},
   "source": [
    "如果训练集非常的不平衡，某些类实例过多而另一些实例过少。那么在调用fit()方法时设置class_weight参数来设置权重。这会给代表性不足的类更大的权重。如果你需要每个实例的权重，设置sample_weight参数。你还可以通过validation_data元组的第三项添加到验证集中来提供样本权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0385f48c",
   "metadata": {},
   "source": [
    "fit()方法返回一个Histroy对象，其中包含训练参数(history.params)、经历的轮次列表(history.epoch)，最重要的是包含在训练集和验证集上每个轮次结束时测得的损失和额外指标的字典(histroy.history)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cf5b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3d30855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid()\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ee751",
   "metadata": {},
   "source": [
    "目前模型尚未完全收敛，因为验证损失仍在下降，因此你可以调用fit()方法继续训练。如果你对模型仍不满意应该回头调整超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785469a6",
   "metadata": {},
   "source": [
    "对模型的验证精度感到满意之后，应该在测试集上对其进行评估泛化误差。可以用evaluate()方法完成操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62b507ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 72.7855 - accuracy: 0.8320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[72.7854995727539, 0.8320000171661377]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684539b",
   "metadata": {},
   "source": [
    "### 使用模型进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "393406ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new=X_test[:3]\n",
    "y_prob=model.predict(X_new)\n",
    "y_prob.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b6fc049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26497a",
   "metadata": {},
   "source": [
    "对于每个实例，模型估计从0类到9类的概率。如果你只关心估计概率的最高类，则可以使用predict_classes()方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23c95afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\envs\\ai\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15e9c17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d23109",
   "metadata": {},
   "source": [
    "## 使用顺序API构建回归MLP\n",
    "我们使用加州住房数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b257dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e5de472",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing=fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85cd99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full,X_test,y_train_full,y_test=train_test_split(housing.data,housing.target)\n",
    "X_train,X_valid,y_train,y_valid=train_test_split(X_train_full,y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dff3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar=StandardScaler()\n",
    "X_train=scalar.fit_transform(X_train)\n",
    "X_valid=scalar.transform(X_valid)\n",
    "X_test=scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbbcead8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8233234b",
   "metadata": {},
   "source": [
    "输出层只有一个神经元，并且不使用激活函数，而损失函数是均方误差。由于数据噪声很大，我们只使用比以前少的神经元单层隐藏层，以免过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "920dacf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(30,activation='relu',input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b55004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c95e8b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3080 - val_loss: 0.5537\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 864us/step - loss: 5.2862 - val_loss: 0.4567\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.4339 - val_loss: 0.4899\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.4023 - val_loss: 0.3959\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.3889\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3693 - val_loss: 0.3861\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3819\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.3771 - val_loss: 0.3984\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 767us/step - loss: 0.3806 - val_loss: 0.3848\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 721us/step - loss: 0.3715 - val_loss: 0.3848\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 743us/step - loss: 0.3618 - val_loss: 0.3780\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.3583 - val_loss: 0.3707\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 825us/step - loss: 0.3628 - val_loss: 0.3699\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.3698\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.3709\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 742us/step - loss: 0.3491 - val_loss: 0.3690\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3593 - val_loss: 0.3657\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.3573 - val_loss: 0.3743\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.3590 - val_loss: 0.3700\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 958us/step - loss: 0.3673 - val_loss: 0.3627\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,epochs=20,validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3aac1aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 793us/step - loss: 0.3594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35942110419273376"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623cda9e",
   "metadata": {},
   "source": [
    "## 使用函数式API构建复杂模型\n",
    "<img src=\"./complex.png\" style=\"zoom:40%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92c0e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_=keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1=keras.layers.Dense(30,activation='relu')(input_)\n",
    "hidden2=keras.layers.Dense(30,activation='relu')(hidden1)\n",
    "concat=keras.layers.Concatenate()([input_,hidden2])\n",
    "output=keras.layers.Dense(1)(concat)\n",
    "model=keras.Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df95e95",
   "metadata": {},
   "source": [
    "- 首先创建一个Input对象。这是模型需要输入类型的规范，包括其shape和dtype。\n",
    "- 接下来我们创建一个包含30个神经元的Dense层，使用relu激活函数。创建它后，我们像调用函数一样将其传递给输入。（我们只是告诉keras它应该将各层连接在一起，尚未处理任何实际数据。）\n",
    "- 我们创建第二个隐藏层，然后再次将其用作函数，我们将第一个隐藏层的输入传递给它。\n",
    "- 接下来我们创建一个Concatenate层，再次像函数一样立即使用它来合并输入和第二个隐藏层的输出。\n",
    "- 然后我们创建单个神经元且没有激活函数的输出层。\n",
    "- 最后我们创建一个keras.Model，指定要使用的输入和输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e315d476",
   "metadata": {},
   "source": [
    "但是如果你想通过宽路径送入特征的子集，而通过深路径送入特征的另一个子集（可能有重合）怎么做？一种解决办法是多个输入。\n",
    "<img src=\"./complex2.png\" style=\"zoom:40%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a27694b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A=keras.layers.Input(shape=[5],name='wide_input')\n",
    "input_B=keras.layers.Input(shape=[6],name='deep_input')\n",
    "hidden1=keras.layers.Dense(30,activation='relu')(input_B)\n",
    "hidden2=keras.layers.Dense(30,activation='relu')(hidden1)\n",
    "concat=keras.layers.Concatenate()([input_A,hidden2])\n",
    "output=keras.layers.Dense(1)(concat)\n",
    "model=keras.Model(inputs=[input_A,input_B],outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eabc10",
   "metadata": {},
   "source": [
    "编译时与往常相同。但是使用fit()方法时，必须传递一对矩阵(X_train_A,X_train_B)，各输入一个矩阵，而不是传递单个矩阵X_train。当你调用predict和evaluate时同样如此。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af94d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3ad05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A,X_train_B=X_train[:,:5],X_train[:,2:]\n",
    "X_valid_A,X_valid_B=X_valid[:,:5],X_valid[:,2:]\n",
    "X_test_A,X_test_B=X_test[:,:5],X_test[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2dbd77c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 3.2501 - val_loss: 0.9518\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8819 - val_loss: 0.7801\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7468 - val_loss: 0.7057\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6830 - val_loss: 0.6600\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6560 - val_loss: 0.6298\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5960 - val_loss: 0.5967\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5866 - val_loss: 0.5752\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.5573 - val_loss: 0.5593\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.5537 - val_loss: 0.5449\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.5412 - val_loss: 0.5703\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.5061 - val_loss: 0.5218\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5221 - val_loss: 0.5382\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4970 - val_loss: 0.5220\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4822 - val_loss: 0.5015\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 0.4960\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4807 - val_loss: 0.4949\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4630 - val_loss: 0.4883\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.4632 - val_loss: 0.4911\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.4604 - val_loss: 0.4802\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 822us/step - loss: 0.4599 - val_loss: 0.4763\n"
     ]
    }
   ],
   "source": [
    "history=model.fit((X_train_A,X_train_B),y_train,epochs=20,validation_data=((X_valid_A,X_valid_B),y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0349ae84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid()\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74bcccf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 664us/step - loss: 0.4765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47649243474006653"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate((X_test_A,X_test_B),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b424506",
   "metadata": {},
   "source": [
    "<img src=\"./complex3.png\" style=\"zoom:30%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca514a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A=keras.layers.Input(shape=[5],name='wide_input')\n",
    "input_B=keras.layers.Input(shape=[6],name='deep_input')\n",
    "hidden1=keras.layers.Dense(30,activation='relu')(input_B)\n",
    "hidden2=keras.layers.Dense(30,activation='relu')(hidden1)\n",
    "concat=keras.layers.concatenate([input_A,hidden2])\n",
    "output=keras.layers.Dense(1,name='main_output')(concat)\n",
    "aux_output=keras.layers.Dense(1,name='aux_output')(hidden2)\n",
    "model=keras.Model(inputs=[input_A,input_B],outputs=[output,aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f51cd",
   "metadata": {},
   "source": [
    "- 每个输出都应该有自己的损失。\n",
    "- 默认情况下，keras将这些损失进行简单的累加即可得到训练的最终损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f7760",
   "metadata": {},
   "source": [
    "我们更关心的是主要输出而不是辅助输出(因为它仅用于正则化)，因此我们要给主要输出损失更大的权值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34a62012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss=['mse','mse'],loss_weights=[0.9,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e38e0365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6322 - main_output_loss: 1.4290 - aux_output_loss: 3.4601 - val_loss: 0.6291 - val_main_output_loss: 0.5525 - val_aux_output_loss: 1.3186\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7706 - main_output_loss: 0.7140 - aux_output_loss: 1.2799 - val_loss: 0.5861 - val_main_output_loss: 0.5214 - val_aux_output_loss: 1.1682\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5467 - main_output_loss: 0.4850 - aux_output_loss: 1.1026 - val_loss: 0.5188 - val_main_output_loss: 0.4635 - val_aux_output_loss: 1.0170\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5091 - main_output_loss: 0.4594 - aux_output_loss: 0.9564 - val_loss: 0.4992 - val_main_output_loss: 0.4556 - val_aux_output_loss: 0.8921\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4834 - main_output_loss: 0.4409 - aux_output_loss: 0.8660 - val_loss: 0.4688 - val_main_output_loss: 0.4320 - val_aux_output_loss: 0.7997\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4510 - main_output_loss: 0.4168 - aux_output_loss: 0.7586 - val_loss: 0.4876 - val_main_output_loss: 0.4591 - val_aux_output_loss: 0.7437\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4686 - main_output_loss: 0.4411 - aux_output_loss: 0.7160 - val_loss: 0.4425 - val_main_output_loss: 0.4152 - val_aux_output_loss: 0.6876\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4416 - main_output_loss: 0.4155 - aux_output_loss: 0.6761 - val_loss: 0.6267 - val_main_output_loss: 0.6165 - val_aux_output_loss: 0.7181\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4451 - main_output_loss: 0.4229 - aux_output_loss: 0.6446 - val_loss: 0.4337 - val_main_output_loss: 0.4115 - val_aux_output_loss: 0.6341\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4115 - main_output_loss: 0.3911 - aux_output_loss: 0.5951 - val_loss: 0.4253 - val_main_output_loss: 0.4037 - val_aux_output_loss: 0.6195\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4175 - main_output_loss: 0.3973 - aux_output_loss: 0.5992 - val_loss: 0.4076 - val_main_output_loss: 0.3860 - val_aux_output_loss: 0.6023\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4096 - main_output_loss: 0.3923 - aux_output_loss: 0.5653 - val_loss: 0.4042 - val_main_output_loss: 0.3831 - val_aux_output_loss: 0.5936\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4100 - main_output_loss: 0.3903 - aux_output_loss: 0.5878 - val_loss: 0.4071 - val_main_output_loss: 0.3872 - val_aux_output_loss: 0.5861\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3928 - main_output_loss: 0.3745 - aux_output_loss: 0.5574 - val_loss: 0.3951 - val_main_output_loss: 0.3752 - val_aux_output_loss: 0.5742\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3959 - main_output_loss: 0.3788 - aux_output_loss: 0.5492 - val_loss: 0.3922 - val_main_output_loss: 0.3731 - val_aux_output_loss: 0.5645\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3935 - main_output_loss: 0.3757 - aux_output_loss: 0.5539 - val_loss: 0.3818 - val_main_output_loss: 0.3625 - val_aux_output_loss: 0.5560\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3632 - main_output_loss: 0.3459 - aux_output_loss: 0.5186 - val_loss: 0.3791 - val_main_output_loss: 0.3604 - val_aux_output_loss: 0.5472\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3779 - main_output_loss: 0.3612 - aux_output_loss: 0.5285 - val_loss: 0.3759 - val_main_output_loss: 0.3575 - val_aux_output_loss: 0.5412\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3765 - main_output_loss: 0.3613 - aux_output_loss: 0.5127 - val_loss: 0.3724 - val_main_output_loss: 0.3545 - val_aux_output_loss: 0.5333\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3846 - main_output_loss: 0.3697 - aux_output_loss: 0.5187 - val_loss: 0.3680 - val_main_output_loss: 0.3507 - val_aux_output_loss: 0.5241\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([X_train_A,X_train_B],[y_train,y_train],epochs=20,validation_data=([X_valid_A,X_valid_B],[y_valid,y_valid]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3396c70",
   "metadata": {},
   "source": [
    "当评估模型时，keras将返回总损失和单个损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "549e374c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 859us/step - loss: 0.3712 - main_output_loss: 0.3551 - aux_output_loss: 0.5163\n"
     ]
    }
   ],
   "source": [
    "total_loss,main_loss,aux_loss=model.evaluate([X_test_A,X_test_B],[y_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3eae24c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3712257444858551, 0.35510820150375366, 0.516282320022583)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss,main_loss,aux_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59feee",
   "metadata": {},
   "source": [
    "## 使用子类API构建动态模型\n",
    "- 顺序式api和函数式api都是声明性质的。\n",
    "- 只需对Model类进行子类化，在构造函数中创建所需要的层，然后再call方法中执行所需要的层即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5dd8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self,units=30,activation='relu',**kwargs):\n",
    "        super().__init__(**kwargs) # 处理标准参数\n",
    "        self.hidden1=keras.layers.Dense(units,activation=activation)\n",
    "        self.hidden2=keras.layers.Dense(units,activation=activation)\n",
    "        self.main_output=keras.layers.Dense(1)\n",
    "        self.aux_output=keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        input_A,input_B=inputs\n",
    "        hidden1=self.hidden1(input_B)\n",
    "        hidden2=self.hidden2(hidden1)\n",
    "        concat=keras.layers.concatenate([input_A,hidden2])\n",
    "        main_output=self.main_output(concat)\n",
    "        aux_output=self.aux_output(hidden2)\n",
    "        return main_output,aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1c82b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af8f05",
   "metadata": {},
   "source": [
    "## 保存和还原模型\n",
    "keras使用HDF5的格式保存模型的结构和每一层的所有模型参数值。它还可以保存优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9015eb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.4213 - val_loss: 0.5360\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.5993 - val_loss: 0.4829\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.4509 - val_loss: 0.4502\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.4524 - val_loss: 0.4344\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.4218 - val_loss: 0.4257\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.4068 - val_loss: 0.4457\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 885us/step - loss: 0.4162 - val_loss: 0.4134\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.3960 - val_loss: 0.4018\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.3809 - val_loss: 0.4000\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3883 - val_loss: 0.3913\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3766 - val_loss: 0.3887\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.3741 - val_loss: 0.3893\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.3758 - val_loss: 0.3852\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 888us/step - loss: 0.3662 - val_loss: 0.3818\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3603 - val_loss: 0.3797\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.3624 - val_loss: 0.3772\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3637 - val_loss: 0.3729\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 885us/step - loss: 0.3537 - val_loss: 0.3711\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3382 - val_loss: 0.3730\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.3582 - val_loss: 0.3723\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(30,activation='relu',input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile(optimizer='sgd',loss='mean_squared_error')\n",
    "history=model.fit(X_train,y_train,epochs=20,validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c787687",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(filepath='my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eedf31",
   "metadata": {},
   "source": [
    "加载模型同样简单。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ebe69384",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model(filepath='./my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb531639",
   "metadata": {},
   "source": [
    "如果一次模型训练要训练几个小时，这种情况下不仅应该在训练结束时保存模型，还应该在训练过程中定期保存检查点。使用回调来告诉fit()方法定期保存检查点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3b31a",
   "metadata": {},
   "source": [
    "## 使用回调函数\n",
    "- fit()方法接受一个callbacks参数，该参数使你可以指定keras在训练开始和结束时，每个轮次开始和结束时(甚至在处理每个批量之前和之后)将调用的对象列表。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9537b4",
   "metadata": {},
   "source": [
    "例如，在训练期间ModelCheckpoint回调会定期保存模型的检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b8ff8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(30,activation='relu',input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile(optimizer='sgd',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b916837f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 643us/step - loss: 1.2981\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 690us/step - loss: 0.6706\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 661us/step - loss: 0.5132\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.4392\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 693us/step - loss: 0.4383\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 696us/step - loss: 0.4320\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 673us/step - loss: 0.4061\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 681us/step - loss: 0.3849\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.3940\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.3838\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb=keras.callbacks.ModelCheckpoint(filepath='my_keras_model.h5')\n",
    "history=model.fit(X_train,y_train,epochs=10,callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25341f41",
   "metadata": {},
   "source": [
    "此外如果在训练期间使用验证集，则可以在创建ModelCheckpoint时设置save_best_only=True。只有当验证集上的模型性能达到目前最好时，它才会保存模型。这样就不必担心训练时间过长而产生过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68d288a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3884 - val_loss: 0.3978\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3852 - val_loss: 0.3943\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3814 - val_loss: 0.4013\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.3852 - val_loss: 0.3870\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3792 - val_loss: 0.3826\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 853us/step - loss: 0.3759 - val_loss: 0.3810\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.3701 - val_loss: 0.3815\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3656 - val_loss: 0.3810\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.3652 - val_loss: 0.3793\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.3691 - val_loss: 0.3752\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.3605 - val_loss: 0.3714\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.3595 - val_loss: 0.3712\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.3619 - val_loss: 0.6763\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.371 - 0s 929us/step - loss: 0.3700 - val_loss: 0.3699\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3541 - val_loss: 0.3663\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3531 - val_loss: 0.3915\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3534 - val_loss: 0.3669\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3536 - val_loss: 0.3640\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3807 - val_loss: 0.3599\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.3485 - val_loss: 0.3611\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb=keras.callbacks.ModelCheckpoint(filepath='my_keras_model.h5',save_best_only=True)\n",
    "history=model.fit(X_train,y_train,epochs=20,validation_data=(X_valid,y_valid),callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b43a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回滚到最优模型\n",
    "model=keras.models.load_model('./my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5f881",
   "metadata": {},
   "source": [
    "实现提前停止的另一种方法是使用EarlyStopping回调。如果在多个轮次(由patience参数定义)的验证集没有任何进展，它将中断训练，并且可以回滚到最优模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5414675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb=keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aee0f4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3481 - val_loss: 0.3838\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 839us/step - loss: 0.3631 - val_loss: 0.3653\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3492 - val_loss: 0.3631\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 863us/step - loss: 0.3467 - val_loss: 0.3630\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 877us/step - loss: 0.3517 - val_loss: 0.3579\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.3440 - val_loss: 0.3623\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.3431 - val_loss: 0.3533\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 911us/step - loss: 0.3481 - val_loss: 0.4010\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.3439 - val_loss: 0.3486\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3447 - val_loss: 0.3476\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.3538 - val_loss: 0.3469\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 883us/step - loss: 0.3405 - val_loss: 0.3430\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.3380 - val_loss: 0.3452\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.3342 - val_loss: 0.3469\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3385 - val_loss: 1.1359\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 891us/step - loss: 0.3492 - val_loss: 0.3542\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3364 - val_loss: 0.3414\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.3335 - val_loss: 0.3423\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.3337 - val_loss: 0.3446\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3296 - val_loss: 0.3356\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.3296 - val_loss: 0.3388\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3619 - val_loss: 0.3357\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 911us/step - loss: 0.3279 - val_loss: 0.3551\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.3262 - val_loss: 0.3420\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 916us/step - loss: 0.3252 - val_loss: 0.3376\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.3268 - val_loss: 0.3356\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.3320 - val_loss: 0.3382\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3438 - val_loss: 0.3333\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 907us/step - loss: 0.3261 - val_loss: 0.3341\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 933us/step - loss: 0.3230 - val_loss: 0.3330\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.3259 - val_loss: 0.3331\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 922us/step - loss: 0.3283 - val_loss: 0.3298\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.3239 - val_loss: 0.3435\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.3279 - val_loss: 0.3324\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.3245 - val_loss: 0.3330\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3215 - val_loss: 0.3339\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 906us/step - loss: 0.3249 - val_loss: 0.3270\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.3177 - val_loss: 0.3278\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.3256 - val_loss: 0.3291\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.3176 - val_loss: 0.3288\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3203 - val_loss: 0.3336\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 929us/step - loss: 0.3330 - val_loss: 0.3265\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 888us/step - loss: 0.3172 - val_loss: 0.3238\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3168 - val_loss: 0.3266\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3173 - val_loss: 0.3298\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 799us/step - loss: 0.3159 - val_loss: 0.3254\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.3155 - val_loss: 0.3461\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.3167 - val_loss: 0.3325\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3201 - val_loss: 0.3260\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.3150 - val_loss: 0.3303\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 902us/step - loss: 0.3283 - val_loss: 0.3259\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 903us/step - loss: 0.3159 - val_loss: 0.3240\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 902us/step - loss: 0.3144 - val_loss: 0.3297\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,epochs=100,validation_data=(X_valid,y_valid),callbacks=[checkpoint_cb,early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36451f0f",
   "metadata": {},
   "source": [
    "## 使用TensorBoard进行可视化\n",
    "- tensorboard可用于在训练期间查看学习曲线；比较多次运行的学习曲线；可视化计算图；分析训练统计数据；查看由模型生成的图像；把复杂的多维数据投影到3D并自动进行聚类，等等。\n",
    "- 要是用它必须修改程序以便将可视化的数据输出到名为事件文件的特殊二进制日志文件中。每个二进制数据记录称为摘要。通常你要把Tensorflow服务器指向根日志目录并配置程序，以使在每次运行时都写入不同的子目录。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0b6d1",
   "metadata": {},
   "source": [
    "首先让我们定义用于TensorBoard日志的根日志目录，再加上一个将根据当前日期和时间生成一个子目录的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15ee5ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir=os.path.join(os.curdir,'my_logs')\n",
    "# os.curdir操作系统用来引用当前目录的常量字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed6c691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id=time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir,run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ad7791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir=get_run_logdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e7690e",
   "metadata": {},
   "source": [
    "使用Keras的TensorBoard回调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53ba66dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(30,activation='relu',input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile(optimizer='sgd',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "240b52d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2591 - val_loss: 0.5214\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5847 - val_loss: 0.4743\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.6835 - val_loss: 0.4589\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.4323 - val_loss: 0.4398\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 941us/step - loss: 0.4369 - val_loss: 0.4318\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.4228 - val_loss: 0.4253\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.4055 - val_loss: 0.4133\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 962us/step - loss: 0.3999 - val_loss: 0.4162\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 939us/step - loss: 0.3958 - val_loss: 0.4018\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3970\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3906 - val_loss: 0.3986\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.3762 - val_loss: 0.3932\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 924us/step - loss: 0.3777 - val_loss: 0.3945\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.3942 - val_loss: 0.3990\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3865 - val_loss: 0.3873\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 883us/step - loss: 0.3860 - val_loss: 0.3839\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 922us/step - loss: 0.3749 - val_loss: 0.3888\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.3726 - val_loss: 0.5313\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 794us/step - loss: 0.3898 - val_loss: 0.3979\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 787us/step - loss: 0.3789 - val_loss: 0.3985\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 756us/step - loss: 0.4430 - val_loss: 0.3816\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 835us/step - loss: 0.3695 - val_loss: 0.4522\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.3650 - val_loss: 0.3788\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.3745 - val_loss: 0.4172\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3773\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 980us/step - loss: 0.3635 - val_loss: 0.3768\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.3824\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.3549 - val_loss: 0.3792\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 786us/step - loss: 0.3815 - val_loss: 0.3759\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3712 - val_loss: 0.3744\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb=keras.callbacks.TensorBoard(run_logdir)\n",
    "history=model.fit(X_train,y_train,epochs=30,validation_data=(X_valid,y_valid),callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b721ddd7",
   "metadata": {},
   "source": [
    "## 微调神经网络超参数\n",
    "- 我们可以使用网格搜索或者随机搜索来探寻超参数空间。\n",
    "- 为此我们要将keras模型包装在模仿常规sklearn回归器的对象中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00515dda",
   "metadata": {},
   "source": [
    "**第一步**是创建一个函数，该函数将在给定一组超参数的情况下构建并编译模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dd01e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1,n_neurons=30,learning_rate=3e-3,input_shape=[8]):\n",
    "    model=keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons,activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a88e14",
   "metadata": {},
   "source": [
    "**第二步**我们基于build_model函数创建一个kerasregressor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1284ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.wrappers.scikit_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6983cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg=keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f4a33",
   "metadata": {},
   "source": [
    "kerasregressor对象是使用build_model()构建的一个keras模型的一个包装。由于构建时未使用任何超参数，它使用默认超参数。现在我们能像sklearn回归器一样使用该对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36d0e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 3.0233 - val_loss: 0.6946\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 812us/step - loss: 0.6724 - val_loss: 0.6033\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.5730 - val_loss: 0.5621\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 795us/step - loss: 0.5172 - val_loss: 0.5295\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 843us/step - loss: 0.4993 - val_loss: 0.5087\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 839us/step - loss: 0.4902 - val_loss: 0.4936\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.4821 - val_loss: 0.4855\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4969 - val_loss: 0.4777\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 885us/step - loss: 0.4633 - val_loss: 0.4704\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4548 - val_loss: 0.4634\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.4508 - val_loss: 0.4585\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.4463 - val_loss: 0.4549\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.4219 - val_loss: 0.4496\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.4415 - val_loss: 0.4456\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 795us/step - loss: 0.4167 - val_loss: 0.4423\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 951us/step - loss: 0.4188 - val_loss: 0.4377\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.4353 - val_loss: 0.4343\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.4287 - val_loss: 0.4340\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.4201 - val_loss: 0.4300\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 787us/step - loss: 0.4112 - val_loss: 0.4277\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 805us/step - loss: 0.4191 - val_loss: 0.4236\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 806us/step - loss: 0.4154 - val_loss: 0.4216\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.4150 - val_loss: 0.4189\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 824us/step - loss: 0.3955 - val_loss: 0.4175\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.4015 - val_loss: 0.4157\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.4058 - val_loss: 0.4126\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 802us/step - loss: 0.3830 - val_loss: 0.4104\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.3968 - val_loss: 0.4079\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.4062 - val_loss: 0.4089\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 823us/step - loss: 0.3801 - val_loss: 0.4059\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.3876 - val_loss: 0.4028\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 852us/step - loss: 0.3756 - val_loss: 0.4017\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 846us/step - loss: 0.3790 - val_loss: 0.4011\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 802us/step - loss: 0.3762 - val_loss: 0.3983\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 775us/step - loss: 0.3784 - val_loss: 0.3980\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 819us/step - loss: 0.3779 - val_loss: 0.3965\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 810us/step - loss: 0.3934 - val_loss: 0.3961\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.3830 - val_loss: 0.3941\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.3744 - val_loss: 0.3934\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 814us/step - loss: 0.3804 - val_loss: 0.3919\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 774us/step - loss: 0.3615 - val_loss: 0.3902\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.3705 - val_loss: 0.3905\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 885us/step - loss: 0.3694 - val_loss: 0.3905\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 781us/step - loss: 0.3724 - val_loss: 0.3900\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3801 - val_loss: 0.3866\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.3692 - val_loss: 0.3872\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.3627 - val_loss: 0.3849\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 836us/step - loss: 0.3664 - val_loss: 0.3844\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 783us/step - loss: 0.3716 - val_loss: 0.3839\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 844us/step - loss: 0.3611 - val_loss: 0.3844\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 827us/step - loss: 0.3587 - val_loss: 0.3838\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 961us/step - loss: 0.3590 - val_loss: 0.3823\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.3817\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 844us/step - loss: 0.3573 - val_loss: 0.3800\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 800us/step - loss: 0.3569 - val_loss: 0.3787\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.3672 - val_loss: 0.3789\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3461 - val_loss: 0.3772\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3774\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 949us/step - loss: 0.3619 - val_loss: 0.3763\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.3602 - val_loss: 0.3752\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3437 - val_loss: 0.3739\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.3604 - val_loss: 0.3731\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 819us/step - loss: 0.3501 - val_loss: 0.3740\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.3570 - val_loss: 0.3729\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 888us/step - loss: 0.3475 - val_loss: 0.3716\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3511 - val_loss: 0.3730\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.3514 - val_loss: 0.3707\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.3557 - val_loss: 0.3710\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 0.3697\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 770us/step - loss: 0.3560 - val_loss: 0.3703\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3390 - val_loss: 0.3700\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 805us/step - loss: 0.3563 - val_loss: 0.3680\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.3461 - val_loss: 0.3706\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 827us/step - loss: 0.3520 - val_loss: 0.3671\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 831us/step - loss: 0.3480 - val_loss: 0.3673\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 836us/step - loss: 0.3427 - val_loss: 0.3660\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.3385 - val_loss: 0.3671\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.3428 - val_loss: 0.3644\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 827us/step - loss: 0.3457 - val_loss: 0.3650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 753us/step - loss: 0.3510 - val_loss: 0.3702\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 769us/step - loss: 0.3512 - val_loss: 0.3646\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.3416 - val_loss: 0.3636\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 733us/step - loss: 0.3399 - val_loss: 0.3647\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 738us/step - loss: 0.3469 - val_loss: 0.3618\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 754us/step - loss: 0.3448 - val_loss: 0.3618\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 739us/step - loss: 0.3449 - val_loss: 0.3618\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 765us/step - loss: 0.3496 - val_loss: 0.3610\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 736us/step - loss: 0.3443 - val_loss: 0.3603\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 747us/step - loss: 0.3532 - val_loss: 0.3593\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 738us/step - loss: 0.3320 - val_loss: 0.3598\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 737us/step - loss: 0.3305 - val_loss: 0.3584\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 770us/step - loss: 0.3477 - val_loss: 0.3578\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 742us/step - loss: 0.3334 - val_loss: 0.3589\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 812us/step - loss: 0.3441 - val_loss: 0.3567\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 761us/step - loss: 0.3336 - val_loss: 0.3563\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 722us/step - loss: 0.3349 - val_loss: 0.3563\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.3212 - val_loss: 0.3572\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 730us/step - loss: 0.3484 - val_loss: 0.3565\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.343 - 0s 782us/step - loss: 0.3436 - val_loss: 0.3557\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.3335 - val_loss: 0.3558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f98a4e9788>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train,y_train,validation_data=(X_valid,y_valid),epochs=100,callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1590aa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 737us/step - loss: 0.3504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.35037633776664734"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6281c411",
   "metadata": {},
   "source": [
    "使用随机搜索较好与网格搜索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19424eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9c2e5310",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0,1,2,3],\n",
    "    'n_neurons':np.arange(1,100),\n",
    "    'learning_rate':reciprocal(3e-4,3e-2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1396f591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.7041 - val_loss: 1.7775\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 1.5217 - val_loss: 0.9533\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.9123 - val_loss: 0.8075\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7968 - val_loss: 0.7577\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.7691 - val_loss: 0.7311\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.7141 - val_loss: 0.7130\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.7120 - val_loss: 0.6983\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6874 - val_loss: 0.6849\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6684 - val_loss: 0.6731\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.6650 - val_loss: 0.6621\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6377 - val_loss: 0.6520\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.6393 - val_loss: 0.6420\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.6414 - val_loss: 0.6329\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6058 - val_loss: 0.6238\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.6202 - val_loss: 0.6155\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.6295 - val_loss: 0.6066\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6051 - val_loss: 0.5984\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.6075 - val_loss: 0.5910\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5902 - val_loss: 0.5834\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5632 - val_loss: 0.5758\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.5667 - val_loss: 0.5689\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.5623 - val_loss: 0.5623\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.5591 - val_loss: 0.5556\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.5572 - val_loss: 0.5493\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.5570 - val_loss: 0.5435\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.5388 - val_loss: 0.5373\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.5183 - val_loss: 0.5316\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.5367 - val_loss: 0.5264\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.5109 - val_loss: 0.5213\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.5170 - val_loss: 0.5162\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4967 - val_loss: 0.5113\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5014 - val_loss: 0.5069\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5020 - val_loss: 0.5027\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.4992 - val_loss: 0.4988\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4835 - val_loss: 0.4950\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4887 - val_loss: 0.4914\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4597 - val_loss: 0.4882\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.499 - 0s 936us/step - loss: 0.4980 - val_loss: 0.4850\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.4784 - val_loss: 0.4822\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4798 - val_loss: 0.4793\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.4745 - val_loss: 0.4768\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4530 - val_loss: 0.4744\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4501 - val_loss: 0.4721\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4592 - val_loss: 0.4696\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.4422 - val_loss: 0.4672\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.4589 - val_loss: 0.4650\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4507 - val_loss: 0.4632\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.4499 - val_loss: 0.4615\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.4439 - val_loss: 0.4600\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4581 - val_loss: 0.4586\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4657 - val_loss: 0.4567\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4524 - val_loss: 0.4550\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4480 - val_loss: 0.4536\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.4446 - val_loss: 0.4525\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.4174 - val_loss: 0.4508\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4232 - val_loss: 0.4493\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.4482\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4317 - val_loss: 0.4472\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4326 - val_loss: 0.4460\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4399 - val_loss: 0.4443\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.4383 - val_loss: 0.4433\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4193 - val_loss: 0.4423\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.4407\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.4401\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.4269 - val_loss: 0.4389\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 0.4381\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4120 - val_loss: 0.4369\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.4357\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4068 - val_loss: 0.4352\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.4247 - val_loss: 0.4337\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.4263 - val_loss: 0.4329\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.4323\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4212 - val_loss: 0.4314\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4269 - val_loss: 0.4304\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.4172 - val_loss: 0.4296\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4212 - val_loss: 0.4288\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.4282\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.4098 - val_loss: 0.4273\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4233 - val_loss: 0.4265\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.4257\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4266 - val_loss: 0.4247\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.4130 - val_loss: 0.4241\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.4114 - val_loss: 0.4235\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.4135 - val_loss: 0.4229\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.4027 - val_loss: 0.4221\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.4215\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.4186 - val_loss: 0.4211\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4006 - val_loss: 0.4201\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3904 - val_loss: 0.4191\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.4240 - val_loss: 0.4187\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.4177\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.4132 - val_loss: 0.4172\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4158 - val_loss: 0.4166\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.4179 - val_loss: 0.4161\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.4157\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3996 - val_loss: 0.4150\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.4143\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3952 - val_loss: 0.4137\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4055 - val_loss: 0.4131\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4081 - val_loss: 0.4123\n",
      "121/121 [==============================] - 0s 573us/step - loss: 0.4033\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.6379 - val_loss: 1.7882\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5025 - val_loss: 1.1568\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0648 - val_loss: 0.9122\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8722 - val_loss: 0.8040\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7849 - val_loss: 0.7486\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6911 - val_loss: 0.7148\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.6629 - val_loss: 0.6916\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.6719 - val_loss: 0.6736\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6505 - val_loss: 0.6582\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.6148 - val_loss: 0.6446\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.6004 - val_loss: 0.6321\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.6077 - val_loss: 0.6205\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.6010 - val_loss: 0.6097\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.5788 - val_loss: 0.6001\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.5659 - val_loss: 0.5912\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.6010 - val_loss: 0.5829\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5431 - val_loss: 0.5746\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5563 - val_loss: 0.5669\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.5427 - val_loss: 0.5600\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.5206 - val_loss: 0.5533\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5240 - val_loss: 0.5470\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.5065 - val_loss: 0.5414\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5007 - val_loss: 0.5358\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5211 - val_loss: 0.5304\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.5041 - val_loss: 0.5254\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5038 - val_loss: 0.5208\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.5189 - val_loss: 0.5163\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.5070 - val_loss: 0.5120\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4994 - val_loss: 0.5083\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.5001 - val_loss: 0.5045\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4929 - val_loss: 0.5011\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4697 - val_loss: 0.4978\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.4765 - val_loss: 0.4944\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4919 - val_loss: 0.4912\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.4731 - val_loss: 0.4885\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4572 - val_loss: 0.4856\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.4517 - val_loss: 0.4827\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4704 - val_loss: 0.4801\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4576 - val_loss: 0.4778\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4434 - val_loss: 0.4755\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.4711 - val_loss: 0.4730\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4560 - val_loss: 0.4711\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4626 - val_loss: 0.4689\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.4314 - val_loss: 0.4670\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.4650\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4631\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4488 - val_loss: 0.4613\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4596\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.4448 - val_loss: 0.4579\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4439 - val_loss: 0.4561\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.4456 - val_loss: 0.4547\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4323 - val_loss: 0.4530\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4517\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4321 - val_loss: 0.4503\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4259 - val_loss: 0.4487\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4093 - val_loss: 0.4475\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.4274 - val_loss: 0.4461\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4156 - val_loss: 0.4447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.4434\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 0.4422\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4410\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4401\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4387\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4142 - val_loss: 0.4378\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4103 - val_loss: 0.4367\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4171 - val_loss: 0.4357\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.4346\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.4028 - val_loss: 0.4335\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.3995 - val_loss: 0.4324\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.4313\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4305\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.4297\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4194 - val_loss: 0.4286\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.4276\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4018 - val_loss: 0.4268\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.4258\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.4011 - val_loss: 0.4250\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.4005 - val_loss: 0.4241\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.4001 - val_loss: 0.4234\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.4110 - val_loss: 0.4230\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.4218\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.4211\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4088 - val_loss: 0.4200\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.4040 - val_loss: 0.4191\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.4187\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.4177\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4170\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.4163\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.4156\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.4150\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4048 - val_loss: 0.4144\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.4005 - val_loss: 0.4137\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.4129\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.4125\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.4115\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.4108\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.4100\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.4079 - val_loss: 0.4096\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.4090\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.3950 - val_loss: 0.4084\n",
      "121/121 [==============================] - 0s 732us/step - loss: 0.4136\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.8554 - val_loss: 1.9949\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7617 - val_loss: 1.2470\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2136 - val_loss: 0.9740\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.9077 - val_loss: 0.8487\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.8007 - val_loss: 0.7831\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7386 - val_loss: 0.7434\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.7338 - val_loss: 0.7154\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.7110 - val_loss: 0.6942\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6463 - val_loss: 0.6762\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6773 - val_loss: 0.6601\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.6411 - val_loss: 0.6457\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.6444 - val_loss: 0.6326\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6347 - val_loss: 0.6202\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.5805 - val_loss: 0.6089\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5769 - val_loss: 0.5982\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.5833 - val_loss: 0.5882\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5610 - val_loss: 0.5787\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5497 - val_loss: 0.5694\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5554 - val_loss: 0.5612\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.5351 - val_loss: 0.5531\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5311 - val_loss: 0.5456\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5189 - val_loss: 0.5391\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5057 - val_loss: 0.5319\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.5242 - val_loss: 0.5257\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5264 - val_loss: 0.5197\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.4774 - val_loss: 0.5147\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.5199 - val_loss: 0.5090\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.4902 - val_loss: 0.5041\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.5006 - val_loss: 0.4994\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4712 - val_loss: 0.4949\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4886 - val_loss: 0.4909\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.4922 - val_loss: 0.4871\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5080 - val_loss: 0.4835\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4558 - val_loss: 0.4798\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4697 - val_loss: 0.4767\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4732 - val_loss: 0.4737\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.4703 - val_loss: 0.4707\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4796 - val_loss: 0.4682\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4730 - val_loss: 0.4653\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4539 - val_loss: 0.4627\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.4655 - val_loss: 0.4606\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4580\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4596 - val_loss: 0.4562\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.4558 - val_loss: 0.4540\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4465 - val_loss: 0.4520\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4622 - val_loss: 0.4502\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4438 - val_loss: 0.4483\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4371 - val_loss: 0.4466\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4409 - val_loss: 0.4451\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.4583 - val_loss: 0.4433\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.4529 - val_loss: 0.4418\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.4346 - val_loss: 0.4404\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.4609 - val_loss: 0.4388\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.4244 - val_loss: 0.4376\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4360 - val_loss: 0.4363\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4353 - val_loss: 0.4355\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.4219 - val_loss: 0.4342\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.4378 - val_loss: 0.4325\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.4390 - val_loss: 0.4314\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.4290 - val_loss: 0.4303\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4134 - val_loss: 0.4293\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.4281\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.4271 - val_loss: 0.4271\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.4387 - val_loss: 0.4259\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.4136 - val_loss: 0.4251\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.4162 - val_loss: 0.4241\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4280 - val_loss: 0.4231\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.4338 - val_loss: 0.4224\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4237 - val_loss: 0.4212\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.4128 - val_loss: 0.4206\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.4197\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.4354 - val_loss: 0.4186\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.4266 - val_loss: 0.4177\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4242 - val_loss: 0.4168\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.4177 - val_loss: 0.4161\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.4243 - val_loss: 0.4153\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4207 - val_loss: 0.4145\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.3980 - val_loss: 0.4139\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.4144 - val_loss: 0.4131\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.4124\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.4166 - val_loss: 0.4117\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4120 - val_loss: 0.4110\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.3966 - val_loss: 0.4103\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.4097\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3952 - val_loss: 0.4090\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3970 - val_loss: 0.4083\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4100 - val_loss: 0.4077\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4132 - val_loss: 0.4072\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4167 - val_loss: 0.4064\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.4029 - val_loss: 0.4060\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.4053\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4103 - val_loss: 0.4045\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.4040\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3977 - val_loss: 0.4034\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4028\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.4003 - val_loss: 0.4024\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3868 - val_loss: 0.4019\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3949 - val_loss: 0.4014\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.4007\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3948 - val_loss: 0.4001\n",
      "121/121 [==============================] - 0s 731us/step - loss: 0.3886\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.6198 - val_loss: 1.2904\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 1.1578 - val_loss: 0.8777\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8227 - val_loss: 0.7666\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7602 - val_loss: 0.7167\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6947 - val_loss: 0.6808\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6451 - val_loss: 0.6534\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6486 - val_loss: 0.6299\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6103\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.6216 - val_loss: 0.5917\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5617 - val_loss: 0.5760\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5489 - val_loss: 0.5623\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5653 - val_loss: 0.5487\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5337 - val_loss: 0.5384\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5335 - val_loss: 0.5280\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5129 - val_loss: 0.5205\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5075 - val_loss: 0.5111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.4794 - val_loss: 0.5040\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.4706 - val_loss: 0.4975\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.4937 - val_loss: 0.4941\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4907 - val_loss: 0.4875\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4860 - val_loss: 0.4835\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.4555 - val_loss: 0.4789\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.4690 - val_loss: 0.4747\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.4532 - val_loss: 0.4710\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.4640 - val_loss: 0.4671\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4726 - val_loss: 0.4652\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.4558 - val_loss: 0.4612\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4307 - val_loss: 0.4616\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.4361 - val_loss: 0.4553\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.4438 - val_loss: 0.4523\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4492 - val_loss: 0.4507\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.4260 - val_loss: 0.4476\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.4212 - val_loss: 0.4449\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.4385 - val_loss: 0.4440\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.4653 - val_loss: 0.4401\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.4311 - val_loss: 0.4376\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4146 - val_loss: 0.4350\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4073 - val_loss: 0.4351\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.4257 - val_loss: 0.4353\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4210 - val_loss: 0.4311\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.4097 - val_loss: 0.4277\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4220 - val_loss: 0.4257\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.4132 - val_loss: 0.4240\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.4197 - val_loss: 0.4213\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4194 - val_loss: 0.4209\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.4198\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4086 - val_loss: 0.4182\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.4068 - val_loss: 0.4174\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4116 - val_loss: 0.4137\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4129 - val_loss: 0.4134\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3928 - val_loss: 0.4114\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.3965 - val_loss: 0.4109\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.4090 - val_loss: 0.4091\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.4048 - val_loss: 0.4085\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3893 - val_loss: 0.4069\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3939 - val_loss: 0.4056\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3839 - val_loss: 0.4047\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3892 - val_loss: 0.4023\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.3973 - val_loss: 0.4014\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3923 - val_loss: 0.4013\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.3934 - val_loss: 0.3999\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3895 - val_loss: 0.3989\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.3736 - val_loss: 0.3982\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3797 - val_loss: 0.3965\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.3685 - val_loss: 0.3966\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3781 - val_loss: 0.3947\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3704 - val_loss: 0.3941\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3892 - val_loss: 0.3938\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.3925\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3911\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.3738 - val_loss: 0.3902\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.3892\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3550 - val_loss: 0.3885\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.3846 - val_loss: 0.3878\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3800 - val_loss: 0.3876\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.3758 - val_loss: 0.3864\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.3717 - val_loss: 0.3859\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.3679 - val_loss: 0.3854\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3657 - val_loss: 0.3840\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3625 - val_loss: 0.3842\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3816 - val_loss: 0.3828\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3777 - val_loss: 0.3826\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3521 - val_loss: 0.3820\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3431 - val_loss: 0.3811\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.3723 - val_loss: 0.3801\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.3568 - val_loss: 0.3807\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.3698 - val_loss: 0.3810\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3499 - val_loss: 0.3782\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.3569 - val_loss: 0.3783\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3701 - val_loss: 0.3778\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 0.3769\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.3579 - val_loss: 0.3770\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3721 - val_loss: 0.3769\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.3526 - val_loss: 0.3759\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3441 - val_loss: 0.3752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.3426 - val_loss: 0.3763\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3675 - val_loss: 0.3732\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3473 - val_loss: 0.3733\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3478 - val_loss: 0.3737\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3612 - val_loss: 0.3727\n",
      "121/121 [==============================] - 0s 673us/step - loss: 0.3587\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.6826 - val_loss: 1.2315\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0311 - val_loss: 0.8456\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7952 - val_loss: 0.7515\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.6913 - val_loss: 0.7103\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6896 - val_loss: 0.6831\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.6298 - val_loss: 0.6597\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6608 - val_loss: 0.6399\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.6242 - val_loss: 0.6223\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5902 - val_loss: 0.6061\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.5835 - val_loss: 0.5907\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.5571 - val_loss: 0.5771\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5565 - val_loss: 0.5641\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.5437 - val_loss: 0.5519\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5547 - val_loss: 0.5412\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4980 - val_loss: 0.5309\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5113 - val_loss: 0.5212\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5200 - val_loss: 0.5122\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4876 - val_loss: 0.5038\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.486 - 0s 1ms/step - loss: 0.4858 - val_loss: 0.4965\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4832 - val_loss: 0.4894\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4826 - val_loss: 0.4828\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4781 - val_loss: 0.4769\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4697 - val_loss: 0.4717\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4428 - val_loss: 0.4672\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4454 - val_loss: 0.4609\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.4481 - val_loss: 0.4565\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4500 - val_loss: 0.4519\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.4336 - val_loss: 0.4481\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.4251 - val_loss: 0.4447\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4242 - val_loss: 0.4407\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.4351 - val_loss: 0.4377\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4193 - val_loss: 0.4341\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.4229 - val_loss: 0.4310\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4321 - val_loss: 0.4282\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.4259 - val_loss: 0.4256\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.4110 - val_loss: 0.4226\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.4202\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.4183\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.4104 - val_loss: 0.4162\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3922 - val_loss: 0.4138\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3949 - val_loss: 0.4119\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3804 - val_loss: 0.4098\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.3857 - val_loss: 0.4079\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3800 - val_loss: 0.4064\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.3799 - val_loss: 0.4046\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3903 - val_loss: 0.4031\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3938 - val_loss: 0.4016\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3863 - val_loss: 0.4009\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.3794 - val_loss: 0.3991\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.3626 - val_loss: 0.3978\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.3700 - val_loss: 0.3956\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3756 - val_loss: 0.3948\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3711 - val_loss: 0.3936\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3640 - val_loss: 0.3923\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.3681 - val_loss: 0.3913\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3784 - val_loss: 0.3909\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3830 - val_loss: 0.3893\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3682 - val_loss: 0.3885\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3815 - val_loss: 0.3871\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3771 - val_loss: 0.3881\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3781 - val_loss: 0.3856\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3689 - val_loss: 0.3849\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.3566 - val_loss: 0.3834\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3442 - val_loss: 0.3826\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.3600 - val_loss: 0.3822\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3585 - val_loss: 0.3813\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.3572 - val_loss: 0.3802\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3550 - val_loss: 0.3804\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.3791\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3783\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3570 - val_loss: 0.3773\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3687 - val_loss: 0.3777\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3638 - val_loss: 0.3759\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 960us/step - loss: 0.3486 - val_loss: 0.3759\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3740 - val_loss: 0.3751\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3709 - val_loss: 0.3738\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3387 - val_loss: 0.3731\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3646 - val_loss: 0.3730\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.3446 - val_loss: 0.3720\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3336 - val_loss: 0.3715\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3484 - val_loss: 0.3713\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.3469 - val_loss: 0.3703\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.3524 - val_loss: 0.3700\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3471 - val_loss: 0.3702\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.3363 - val_loss: 0.3695\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3427 - val_loss: 0.3676\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3422 - val_loss: 0.3671\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3503 - val_loss: 0.3669\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3320 - val_loss: 0.3661\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3438 - val_loss: 0.3655\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.3236 - val_loss: 0.3656\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3351 - val_loss: 0.3643\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.3514 - val_loss: 0.3642\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3461 - val_loss: 0.3634\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.3588 - val_loss: 0.3634\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.3463 - val_loss: 0.3633\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.3497 - val_loss: 0.3630\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3420 - val_loss: 0.3621\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.3474 - val_loss: 0.3609\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3222 - val_loss: 0.3605\n",
      "121/121 [==============================] - 0s 614us/step - loss: 0.3632\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.1344 - val_loss: 1.2266\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 1.0585 - val_loss: 0.8599\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.7847 - val_loss: 0.7451\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.7225 - val_loss: 0.7041\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.6767 - val_loss: 0.6773\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.6659 - val_loss: 0.6558\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.6094 - val_loss: 0.6375\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.5933 - val_loss: 0.6194\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.6047 - val_loss: 0.6024\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.5878 - val_loss: 0.5865\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5802 - val_loss: 0.5725\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.5172 - val_loss: 0.5599\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5542 - val_loss: 0.5450\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.5426 - val_loss: 0.5336\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5214 - val_loss: 0.5218\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.5068 - val_loss: 0.5114\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.5119 - val_loss: 0.5021\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.5032 - val_loss: 0.4938\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.4625 - val_loss: 0.4848\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4695 - val_loss: 0.4797\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.4487 - val_loss: 0.4720\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.4744 - val_loss: 0.4658\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.4682 - val_loss: 0.4611\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4523 - val_loss: 0.4557\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4408 - val_loss: 0.4514\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4387 - val_loss: 0.4472\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.4137 - val_loss: 0.4427\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.4356 - val_loss: 0.4398\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4252 - val_loss: 0.4363\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4395 - val_loss: 0.4329\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4250 - val_loss: 0.4301\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4151 - val_loss: 0.4274\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.4250\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4340 - val_loss: 0.4231\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.4204\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.4177 - val_loss: 0.4199\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.4035 - val_loss: 0.4178\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4058 - val_loss: 0.4155\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.4187 - val_loss: 0.4136\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4122\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.4056 - val_loss: 0.4103\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4043 - val_loss: 0.4091\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.4108 - val_loss: 0.4102\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3993 - val_loss: 0.4058\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3981 - val_loss: 0.4048\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3866 - val_loss: 0.4047\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3921 - val_loss: 0.4030\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3909 - val_loss: 0.4025\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.4007\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3828 - val_loss: 0.3990\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3733 - val_loss: 0.3988\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 989us/step - loss: 0.4054 - val_loss: 0.3977\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.3902 - val_loss: 0.3966\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.3779 - val_loss: 0.3956\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.3950\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3846 - val_loss: 0.3941\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.3942\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.3844 - val_loss: 0.3937\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3774 - val_loss: 0.3920\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3799 - val_loss: 0.3915\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3622 - val_loss: 0.3899\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3594 - val_loss: 0.3901\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3776 - val_loss: 0.3892\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3960 - val_loss: 0.3874\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.3872\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.3870\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3817 - val_loss: 0.3856\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.3663 - val_loss: 0.3846\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3750 - val_loss: 0.3851\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3692 - val_loss: 0.3833\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3746 - val_loss: 0.3836\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.3815\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3613 - val_loss: 0.3818\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3419 - val_loss: 0.3809\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.3824\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3566 - val_loss: 0.3792\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3616 - val_loss: 0.3782\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3506 - val_loss: 0.3786\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.3534 - val_loss: 0.3787\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3633 - val_loss: 0.3773\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.3524 - val_loss: 0.3765\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3423 - val_loss: 0.3757\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3744\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.3739\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3742\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3495 - val_loss: 0.3730\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3723\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.3718\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3712\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.3632 - val_loss: 0.3709\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3676 - val_loss: 0.3704\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3481 - val_loss: 0.3696\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3402 - val_loss: 0.3694\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3558 - val_loss: 0.3688\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3507 - val_loss: 0.3682\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.3680\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.3567 - val_loss: 0.3673\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3675\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.3665\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3577 - val_loss: 0.3657\n",
      "121/121 [==============================] - 0s 735us/step - loss: 0.3527\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9825 - val_loss: 0.5855\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 573us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1260 - val_loss: 0.4881\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.4586 - val_loss: 0.4323\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.3947 - val_loss: 0.4185\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.3912\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3573 - val_loss: 0.3786\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3604 - val_loss: 0.3725\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3711\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.4068\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3551 - val_loss: 0.3564\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3569\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3435\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 0.3430\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.3210 - val_loss: 0.3577\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3218 - val_loss: 0.3395\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 0.3518\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3391\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3274\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.3528\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2926 - val_loss: 0.3253\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3182\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.3643\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2973 - val_loss: 0.3494\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.3201\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3034 - val_loss: 0.3219\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.2900 - val_loss: 0.3154\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.2989 - val_loss: 0.3100\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.2887 - val_loss: 0.3149\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.2816 - val_loss: 0.3171\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.2654 - val_loss: 0.3376\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.2686 - val_loss: 0.3258\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2728 - val_loss: 0.3168\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.3080\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.3202\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 0.3097\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 0.3498\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2738 - val_loss: 0.3076\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2611 - val_loss: 0.3035\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2617 - val_loss: 0.3210\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2719 - val_loss: 0.3014\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2543 - val_loss: 0.3001\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.3164\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.2663 - val_loss: 0.3139\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.2598 - val_loss: 0.3044\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.2664 - val_loss: 0.3110\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2709 - val_loss: 0.2977\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2517 - val_loss: 0.3185\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2590 - val_loss: 0.3102\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.3115\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2573 - val_loss: 0.3143\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.2581 - val_loss: 0.3103\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2621 - val_loss: 0.3016\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2619 - val_loss: 0.3088\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2609 - val_loss: 0.3469\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.2623 - val_loss: 0.2900\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2529 - val_loss: 0.3153\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.2563 - val_loss: 0.2901\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2472 - val_loss: 0.2983\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2556 - val_loss: 0.3060\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2782 - val_loss: 0.2954\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2485 - val_loss: 0.3075\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.2390 - val_loss: 0.2937\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2574 - val_loss: 0.2988\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2560 - val_loss: 0.2925\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2537 - val_loss: 0.2932\n",
      "121/121 [==============================] - 0s 623us/step - loss: 0.2919\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0478 - val_loss: 0.4747\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4556 - val_loss: 0.4260\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.3971\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3981\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3682\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3589 - val_loss: 0.3614\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3604 - val_loss: 0.3788\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.3585\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3717\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.3479\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.3382\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3272 - val_loss: 0.3287\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3355 - val_loss: 0.3428\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3277\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.3439\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.3178\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3065 - val_loss: 0.3185\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.2972 - val_loss: 0.3136\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.3261 - val_loss: 0.3266\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3148 - val_loss: 0.3206\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3105 - val_loss: 0.3185\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.3039 - val_loss: 0.3089\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 0.2892 - val_loss: 0.3106\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2891 - val_loss: 0.3097\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.2849 - val_loss: 0.3025\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2923 - val_loss: 0.2984\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.2854 - val_loss: 0.3003\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.2787 - val_loss: 0.2983\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.2987 - val_loss: 0.3450\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.2980 - val_loss: 0.3024\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.2781 - val_loss: 0.3265\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.2781 - val_loss: 0.2937\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2750 - val_loss: 0.2982\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.2726 - val_loss: 0.3155\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 956us/step - loss: 0.2861 - val_loss: 0.2921\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.2669 - val_loss: 0.3047\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.2733 - val_loss: 0.3058\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.2673 - val_loss: 0.2895\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.2953 - val_loss: 0.3051\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.2710 - val_loss: 0.3093\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.2683 - val_loss: 0.2979\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.2767 - val_loss: 0.2921\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.2676 - val_loss: 0.3101\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.2543 - val_loss: 0.2965\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.2858 - val_loss: 0.2859\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.2579 - val_loss: 0.2899\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.2729 - val_loss: 0.2879\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.2695 - val_loss: 0.2994\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.2602 - val_loss: 0.2908\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.2683 - val_loss: 0.3154\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2648 - val_loss: 0.2940\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.2692 - val_loss: 0.2923\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.2555 - val_loss: 0.3005\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.2496 - val_loss: 0.2859\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.2657 - val_loss: 0.2821\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.2573 - val_loss: 0.2927\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.2585 - val_loss: 0.2873\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.2545 - val_loss: 0.2863\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.2488 - val_loss: 0.2904\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2478 - val_loss: 0.2904\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2470 - val_loss: 0.2939\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.2660 - val_loss: 0.2842\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.2434 - val_loss: 0.2859\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.2460 - val_loss: 0.2968\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.2560 - val_loss: 0.2929\n",
      "121/121 [==============================] - 0s 564us/step - loss: 0.3041\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8992 - val_loss: 0.6579\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.0089 - val_loss: 60.6244\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 8751.1012 - val_loss: 20010.0469\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 12270765.6298 - val_loss: 6428046.5000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 3429191919.6044 - val_loss: 2085057920.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 83684190213.7942 - val_loss: 683550572544.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 168517795639076.8750 - val_loss: 218150851313664.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 17783007752081290.0000 - val_loss: 70014495275089920.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 10214081892473864192.0000 - val_loss: 28188680978595577856.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 6966593024398598340608.0000 - val_loss: 7037230202136962269184.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 782871602295054912192512.0000 - val_loss: 2267757544345699444850688.0000\n",
      "121/121 [==============================] - 0s 540us/step - loss: 16699963078373259224285184.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.0831 - val_loss: 0.7747\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.6246 - val_loss: 0.5556\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.5692 - val_loss: 0.5434\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.5256 - val_loss: 0.5382\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.5276 - val_loss: 0.5332\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.5322 - val_loss: 0.5261\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.5262 - val_loss: 0.5309\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.5013 - val_loss: 0.5347\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.5157 - val_loss: 0.6274\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.5428 - val_loss: 0.5288\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.5329 - val_loss: 0.5281\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.5354 - val_loss: 0.6060\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.5293 - val_loss: 0.5290\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.5032 - val_loss: 0.5300\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.5025 - val_loss: 0.5339\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.5241 - val_loss: 0.5260\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.5048 - val_loss: 0.5356\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.5464 - val_loss: 0.5320\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.4995 - val_loss: 0.5325\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.5265 - val_loss: 0.5318\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.5332 - val_loss: 0.5318\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5564 - val_loss: 0.5334\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.5310 - val_loss: 0.5337\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.5038 - val_loss: 0.6050\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5169 - val_loss: 0.5541\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.5356 - val_loss: 0.5400\n",
      "121/121 [==============================] - 0s 549us/step - loss: 0.5300\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.2274 - val_loss: 0.6193\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.6529 - val_loss: 0.5540\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 4.8336 - val_loss: 0.6125\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 4.0017 - val_loss: 3.3344\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 1.3313 - val_loss: 0.5670\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 1.8925 - val_loss: 1.1567\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8900 - val_loss: 0.6423\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 0.5278\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.6017 - val_loss: 0.5723\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.6709 - val_loss: 0.5975\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 25.3154 - val_loss: 0.5890\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.8209 - val_loss: 0.5387\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.5208 - val_loss: 0.5262\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2527 - val_loss: 0.5846\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 7.8016 - val_loss: 0.8533\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.7554 - val_loss: 0.6091\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 31.2297 - val_loss: 0.6839\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 2.0332 - val_loss: 0.5630\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.5931 - val_loss: 0.5446\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.5596 - val_loss: 0.5423\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5723 - val_loss: 0.5826\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 16.3838 - val_loss: 0.6274\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 2.4487 - val_loss: 0.5305\n",
      "121/121 [==============================] - 0s 557us/step - loss: 0.5056\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.0256 - val_loss: 0.5292\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 620us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1745 - val_loss: 0.5295\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.4645 - val_loss: 0.8782\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 1.1427 - val_loss: 0.4344\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.4319 - val_loss: 0.4082\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4171 - val_loss: 0.3937\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.3923\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.3823\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.3819\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3560 - val_loss: 0.3682\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3460 - val_loss: 0.3746\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.3400 - val_loss: 0.3645\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3473 - val_loss: 0.3712\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3431 - val_loss: 0.3532\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3254 - val_loss: 0.3620\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3490 - val_loss: 0.3528\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.3423 - val_loss: 0.3517\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3429 - val_loss: 0.3623\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.3507\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3404 - val_loss: 0.3360\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3500 - val_loss: 0.3472\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3365\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.3455 - val_loss: 0.3623\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3356 - val_loss: 0.3327\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.3351 - val_loss: 0.3387\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3374 - val_loss: 0.3306\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3172 - val_loss: 0.3322\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3117 - val_loss: 0.3321\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3282 - val_loss: 0.3333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3114 - val_loss: 0.3344\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3296 - val_loss: 0.3332\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3119 - val_loss: 0.3298\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3051 - val_loss: 0.3278\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.3234 - val_loss: 0.3342\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3154 - val_loss: 0.3428\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3056 - val_loss: 0.3292\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3188 - val_loss: 0.3296\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3101 - val_loss: 0.3227\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3286 - val_loss: 0.3253\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3233 - val_loss: 0.3301\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3008 - val_loss: 0.3306\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3079 - val_loss: 0.3289\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3091 - val_loss: 0.3441\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3155 - val_loss: 0.3325\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3160 - val_loss: 0.3332\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.2982 - val_loss: 0.3367\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.3129 - val_loss: 0.3257\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.3163 - val_loss: 0.3497\n",
      "121/121 [==============================] - 0s 574us/step - loss: 0.4840\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3152 - val_loss: 0.4909\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.4546 - val_loss: 0.4516\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.4184 - val_loss: 0.4172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.4168 - val_loss: 0.4207\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3865 - val_loss: 0.3997\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3720 - val_loss: 0.5422\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4131 - val_loss: 0.3999\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3684 - val_loss: 0.3958\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3933 - val_loss: 0.3965\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.3796 - val_loss: 0.4142\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.3726 - val_loss: 0.3776\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3615 - val_loss: 0.3724\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3682 - val_loss: 0.3753\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3834 - val_loss: 0.3680\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.3794 - val_loss: 0.3661\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.3619 - val_loss: 0.3810\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.3836 - val_loss: 0.3589\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3446 - val_loss: 0.3729\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3439 - val_loss: 0.3557\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3458 - val_loss: 0.3506\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.3495\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.3635\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.3429\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3483\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.3295 - val_loss: 0.3713\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3189 - val_loss: 0.3506\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3177 - val_loss: 0.3502\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3229 - val_loss: 0.3408\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.3716\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3356 - val_loss: 0.3414\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.3340\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.3355\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3334\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3164 - val_loss: 0.3393\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 0.3474\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3421\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3179 - val_loss: 0.3394\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3201 - val_loss: 0.3547\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.3394 - val_loss: 0.3318\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.3226 - val_loss: 0.3342\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3244 - val_loss: 0.3393\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3222 - val_loss: 0.3306\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3153 - val_loss: 0.3355\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3366\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3270\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3116 - val_loss: 0.3460\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3128 - val_loss: 0.3255\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3160 - val_loss: 0.3277\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.3455\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.3281\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.3306\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3038 - val_loss: 0.3571\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 0.3327\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3215 - val_loss: 0.3457\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.3387\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 0.3332\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3144 - val_loss: 0.3312\n",
      "121/121 [==============================] - 0s 556us/step - loss: 0.3318\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9346 - val_loss: 0.4514\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4540 - val_loss: 0.4452\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.3946\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.3936 - val_loss: 0.4183\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.3947\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.3489\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3347 - val_loss: 0.3408\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3356\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 0.3591\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.3750\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3480 - val_loss: 0.3266\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3145 - val_loss: 0.3141\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2890 - val_loss: 0.3056\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3164\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3234 - val_loss: 0.3345\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.3164\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.3079 - val_loss: 0.3195\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.3142\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.3146\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3090\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2952 - val_loss: 0.3161\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2816 - val_loss: 0.3042\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.2869 - val_loss: 0.2952\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2844 - val_loss: 0.3091\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2915 - val_loss: 0.3055\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 968us/step - loss: 0.2704 - val_loss: 0.3033\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2744 - val_loss: 0.3054\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2677 - val_loss: 0.3365\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.2771 - val_loss: 0.3071\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.2829 - val_loss: 0.2965\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.2893 - val_loss: 0.3089\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.2696 - val_loss: 0.3026\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.2830 - val_loss: 0.3143\n",
      "121/121 [==============================] - 0s 549us/step - loss: 0.3063\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9469 - val_loss: 0.4605\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.4270 - val_loss: 0.4834\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.3857 - val_loss: 0.4261\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.3615 - val_loss: 0.4408\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4081 - val_loss: 0.3596\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.3466\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3408 - val_loss: 0.3584\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3322 - val_loss: 0.3980\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3347 - val_loss: 0.3547\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.3357 - val_loss: 0.3382\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3123 - val_loss: 0.3389\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3248 - val_loss: 0.3380\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.3050 - val_loss: 0.3430\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3144 - val_loss: 0.3125\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.2848 - val_loss: 0.3145\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.2988 - val_loss: 0.3689\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.2842 - val_loss: 0.3103\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.3128\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2892 - val_loss: 0.3100\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2742 - val_loss: 0.3831\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2739 - val_loss: 0.3124\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2762 - val_loss: 0.3074\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2773 - val_loss: 0.3127\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2828 - val_loss: 0.3267\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2687 - val_loss: 0.3557\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2589 - val_loss: 0.3299\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2622 - val_loss: 0.2974\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2777 - val_loss: 0.3032\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2724 - val_loss: 0.3094\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2771 - val_loss: 0.3137\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2588 - val_loss: 0.3160\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2677 - val_loss: 0.3109\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2604 - val_loss: 0.2977\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.3177\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2733 - val_loss: 0.3028\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2547 - val_loss: 0.3131\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2634 - val_loss: 0.3336\n",
      "121/121 [==============================] - 0s 698us/step - loss: 0.3314\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1577 - val_loss: 0.4723\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5520 - val_loss: 0.4152\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.4143\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.3893\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3756\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.3643\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3550 - val_loss: 0.3670\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3557 - val_loss: 0.3569\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3266 - val_loss: 0.3732\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3591\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 0.3383\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.3306\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3097 - val_loss: 0.3291\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.3282\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.3050 - val_loss: 0.3370\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2946 - val_loss: 0.3464\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.3564\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2783 - val_loss: 0.3378\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3886\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.3110 - val_loss: 0.3562\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3211 - val_loss: 0.3208\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.3155\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3269\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.3007\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2772 - val_loss: 0.3033\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2707 - val_loss: 0.3035\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 0.3125\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.2797 - val_loss: 0.3077\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2780 - val_loss: 0.3069\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2938 - val_loss: 0.2980\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2684 - val_loss: 0.3230\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.2636 - val_loss: 0.2919\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.2947 - val_loss: 0.2947\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2677 - val_loss: 0.3356\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.2691 - val_loss: 0.3417\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.2572 - val_loss: 0.3210\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.2805 - val_loss: 0.3170\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.2690 - val_loss: 0.3063\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.2576 - val_loss: 0.3261\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2750 - val_loss: 0.2929\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.2512 - val_loss: 0.3143\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.2709 - val_loss: 0.3116\n",
      "121/121 [==============================] - 0s 659us/step - loss: 0.3009\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3788 - val_loss: 0.5941\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 1.0307 - val_loss: 0.4809\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4483 - val_loss: 0.4473\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4282 - val_loss: 0.4088\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.4007\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.3892\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.3914\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3714\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.3846\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3379 - val_loss: 0.3674\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3567\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3418 - val_loss: 0.3646\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.3475\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3256 - val_loss: 0.3401\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3198 - val_loss: 0.3422\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3356 - val_loss: 0.3443\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.3407\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3300 - val_loss: 0.3383\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3266 - val_loss: 0.3519\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3226 - val_loss: 0.3304\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.3392\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3115 - val_loss: 0.3233\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3226\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.2979 - val_loss: 0.3265\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.3187\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3036 - val_loss: 0.3337\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.2927 - val_loss: 0.3193\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 0.3146\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2979 - val_loss: 0.3174\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.3115\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3259\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.3168\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.2832 - val_loss: 0.3161\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.3381\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 0.3053\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.3155\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2727 - val_loss: 0.3145\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.2667 - val_loss: 0.3078\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 0.3120\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.2709 - val_loss: 0.3038\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2922 - val_loss: 0.3100\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.3050\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2688 - val_loss: 0.3335\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2745 - val_loss: 0.3188\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2775 - val_loss: 0.3320\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2682 - val_loss: 0.3338\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2659 - val_loss: 0.3184\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2638 - val_loss: 0.3103\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.2589 - val_loss: 0.3017\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2625 - val_loss: 0.3091\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2662 - val_loss: 0.3039\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.2714 - val_loss: 0.2950\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2634 - val_loss: 0.3190\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.2713 - val_loss: 0.3080\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2602 - val_loss: 0.2983\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2572 - val_loss: 0.2921\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2699 - val_loss: 0.2991\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 0.3004\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.2522 - val_loss: 0.2944\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2557 - val_loss: 0.3041\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.2749 - val_loss: 0.2958\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2519 - val_loss: 0.3054\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2557 - val_loss: 0.3016\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.2591 - val_loss: 0.2905\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2604 - val_loss: 0.3128\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.2664 - val_loss: 0.3247\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.2543 - val_loss: 0.2913\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.3132\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2635 - val_loss: 0.2918\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2548 - val_loss: 0.2939\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2532 - val_loss: 0.3099\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.2431 - val_loss: 0.2976\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2336 - val_loss: 0.2950\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.2627 - val_loss: 0.3153\n",
      "121/121 [==============================] - 0s 640us/step - loss: 0.3149\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2033 - val_loss: 0.5467\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4729 - val_loss: 0.4443\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4353\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4062 - val_loss: 0.4008\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.3953\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 0.3970\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.3716\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3377 - val_loss: 0.3730\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.3560\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3548 - val_loss: 0.3554\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3297 - val_loss: 0.3544\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.3463\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.3513\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3208 - val_loss: 0.3381\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3234 - val_loss: 0.3367\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3089 - val_loss: 0.3335\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3356\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3044 - val_loss: 0.3357\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.3259\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3011 - val_loss: 0.3452\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3154 - val_loss: 0.3359\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2948 - val_loss: 0.3314\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.3868\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 0.3163\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.3172\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 0.3214\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.3110\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2742 - val_loss: 0.3181\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.3198\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2834 - val_loss: 0.3213\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.2783 - val_loss: 0.3113\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2699 - val_loss: 0.3149\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2654 - val_loss: 0.3138\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.2976 - val_loss: 0.3202\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2750 - val_loss: 0.3048\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.2802 - val_loss: 0.3324\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2676 - val_loss: 0.3055\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2726 - val_loss: 0.3086\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2694 - val_loss: 0.3060\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.2694 - val_loss: 0.3353\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2614 - val_loss: 0.3108\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.2673 - val_loss: 0.3270\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 0.3191\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.2689 - val_loss: 0.3365\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2756 - val_loss: 0.3225\n",
      "121/121 [==============================] - 0s 633us/step - loss: 0.3521\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5640 - val_loss: 0.5356\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5060 - val_loss: 0.4460\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4515 - val_loss: 0.4105\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4141 - val_loss: 0.3953\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.3814\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.3786\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.3733\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3481 - val_loss: 0.3640\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.3559\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3252 - val_loss: 0.3565\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3491\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3581\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3271 - val_loss: 0.3408\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3097 - val_loss: 0.3424\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3068 - val_loss: 0.3350\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.3335\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.3284\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.3078 - val_loss: 0.3306\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.3276\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3226\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.3396\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3199 - val_loss: 0.3342\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.3179\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.3144\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.3200\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2822 - val_loss: 0.3130\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.3266\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 0.3349\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.2973 - val_loss: 0.3153\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 0.3262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3137 - val_loss: 0.3221\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.3151\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.2788 - val_loss: 0.3058\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2774 - val_loss: 0.3085\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.2818 - val_loss: 0.3103\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2730 - val_loss: 0.3109\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 0.3136\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2837 - val_loss: 0.3076\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.2703 - val_loss: 0.3096\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2730 - val_loss: 0.3268\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.2857 - val_loss: 0.3122\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.2718 - val_loss: 0.3022\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2705 - val_loss: 0.3041\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.2694 - val_loss: 0.3155\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2881 - val_loss: 0.3077\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.2629 - val_loss: 0.3005\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2484 - val_loss: 0.3047\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2645 - val_loss: 0.3003\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2558 - val_loss: 0.3110\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.2578 - val_loss: 0.3111\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2648 - val_loss: 0.3064\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.3129\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2526 - val_loss: 0.3367\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.2433 - val_loss: 0.2974\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2652 - val_loss: 0.3025\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2618 - val_loss: 0.3075\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.2634 - val_loss: 0.2953\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2565 - val_loss: 0.2989\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2556 - val_loss: 0.3124\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2560 - val_loss: 0.2983\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2571 - val_loss: 0.3050\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2548 - val_loss: 0.2932\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2398 - val_loss: 0.3036\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2689 - val_loss: 0.3010\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2506 - val_loss: 0.3048\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2589 - val_loss: 0.3097\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2494 - val_loss: 0.3020\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2579 - val_loss: 0.3022\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2501 - val_loss: 0.2993\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2521 - val_loss: 0.3014\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2533 - val_loss: 0.2967\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2423 - val_loss: 0.2900\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2574 - val_loss: 0.2952\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2416 - val_loss: 0.3049\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2335 - val_loss: 0.2980\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2396 - val_loss: 0.3001\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2447 - val_loss: 0.2937\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2378 - val_loss: 0.3142\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2366 - val_loss: 0.2897\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2454 - val_loss: 0.2998\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2451 - val_loss: 0.3015\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2457 - val_loss: 0.2994\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2364 - val_loss: 0.3060\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2458 - val_loss: 0.3237\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2398 - val_loss: 0.2919\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2402 - val_loss: 0.2989\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2481 - val_loss: 0.2914\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2412 - val_loss: 0.2876\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2626 - val_loss: 0.2859\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2509 - val_loss: 0.2899\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2280 - val_loss: 0.3036\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2442 - val_loss: 0.2930\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2445 - val_loss: 0.2963\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2399 - val_loss: 0.3024\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2270 - val_loss: 0.2893\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2207 - val_loss: 0.3223\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2349 - val_loss: 0.2931\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2371 - val_loss: 0.2999\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2524 - val_loss: 0.3148\n",
      "121/121 [==============================] - 0s 706us/step - loss: 0.3143\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5736 - val_loss: 1.0588\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9601 - val_loss: 0.7611\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7307 - val_loss: 0.6991\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.6519 - val_loss: 0.6661\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.6562 - val_loss: 0.6413\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.6211\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6033\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5800 - val_loss: 0.5857\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5725 - val_loss: 0.5700\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5466 - val_loss: 0.5573\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5544 - val_loss: 0.5455\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5103 - val_loss: 0.5366\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5226 - val_loss: 0.5259\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5338 - val_loss: 0.5187\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5166 - val_loss: 0.5110\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5097 - val_loss: 0.5058\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5153 - val_loss: 0.4983\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4641 - val_loss: 0.4938\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4555 - val_loss: 0.4892\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4617 - val_loss: 0.4844\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4939 - val_loss: 0.4799\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4530 - val_loss: 0.4766\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4829 - val_loss: 0.4726\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4653 - val_loss: 0.4693\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4658 - val_loss: 0.4665\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4449 - val_loss: 0.4638\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4601\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4496 - val_loss: 0.4579\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4556\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4314 - val_loss: 0.4529\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4503\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.4478\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4456\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4302 - val_loss: 0.4434\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4403 - val_loss: 0.4422\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4152 - val_loss: 0.4402\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4429 - val_loss: 0.4377\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4488 - val_loss: 0.4363\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4364 - val_loss: 0.4348\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.4345\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4309 - val_loss: 0.4324\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4302\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4169 - val_loss: 0.4288\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.4267\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4159 - val_loss: 0.4260\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4181 - val_loss: 0.4240\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4077 - val_loss: 0.4229\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.4259 - val_loss: 0.4212\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4205\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.4188\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.4176\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.4170\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4093 - val_loss: 0.4154\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4182 - val_loss: 0.4140\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.4129\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.4121\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.4107\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.4101\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.4086\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4094\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.4080\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4059\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.4048\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4042\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.4028\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.4017\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.4008\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.4002\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.3990\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3997\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.3981\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.3974\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3970\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3956\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.3940\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3939\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3931\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.3935\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3915\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.3904\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.3910\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.3892\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3892\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.3879\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.3878\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3862\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.3858\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.3857\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3845\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.3840\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3834\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.3827\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3608 - val_loss: 0.3834\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3817\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3551 - val_loss: 0.3821\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3693 - val_loss: 0.3809\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.3799\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3795\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.3787\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3419 - val_loss: 0.3782\n",
      "121/121 [==============================] - 0s 612us/step - loss: 0.3644\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.4984 - val_loss: 1.2190\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0083 - val_loss: 0.8000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7524 - val_loss: 0.7168\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6905 - val_loss: 0.6768\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.6357 - val_loss: 0.6465\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.6293 - val_loss: 0.6209\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.6105 - val_loss: 0.5988\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5773 - val_loss: 0.5790\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5583 - val_loss: 0.5621\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5322 - val_loss: 0.5467\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.5151 - val_loss: 0.5329\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.5025 - val_loss: 0.5201\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.500 - 0s 961us/step - loss: 0.5005 - val_loss: 0.5092\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4854 - val_loss: 0.4991\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4639 - val_loss: 0.4903\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4605 - val_loss: 0.4827\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.4465 - val_loss: 0.4760\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4537 - val_loss: 0.4697\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4544 - val_loss: 0.4642\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4595 - val_loss: 0.4596\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.4487 - val_loss: 0.4548\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4316 - val_loss: 0.4509\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4163 - val_loss: 0.4471\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4556 - val_loss: 0.4438\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4282 - val_loss: 0.4413\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.4152 - val_loss: 0.4379\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.4254 - val_loss: 0.4353\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4194 - val_loss: 0.4325\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.4434 - val_loss: 0.4299\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.4134 - val_loss: 0.4279\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.4043 - val_loss: 0.4257\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3926 - val_loss: 0.4236\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3957 - val_loss: 0.4216\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.4022 - val_loss: 0.4198\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.4106 - val_loss: 0.4184\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4027 - val_loss: 0.4162\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4018 - val_loss: 0.4143\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.4128\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3996 - val_loss: 0.4115\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.4148 - val_loss: 0.4098\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.4083\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.4075\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.4055\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.4046\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.4029\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.4020\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.4014\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3691 - val_loss: 0.3998\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.3986\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3832 - val_loss: 0.3975\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.3963\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.3955\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3741 - val_loss: 0.3942\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3994 - val_loss: 0.3938\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.3925\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3734 - val_loss: 0.3917\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.3689 - val_loss: 0.3907\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3903\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3656 - val_loss: 0.3896\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3656 - val_loss: 0.3883\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3477 - val_loss: 0.3874\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.3698 - val_loss: 0.3864\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.3789 - val_loss: 0.3859\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3655 - val_loss: 0.3853\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.3841\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3616 - val_loss: 0.3837\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3729 - val_loss: 0.3828\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.3679 - val_loss: 0.3827\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 958us/step - loss: 0.3532 - val_loss: 0.3817\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3548 - val_loss: 0.3806\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3464 - val_loss: 0.3806\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.3506 - val_loss: 0.3794\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3459 - val_loss: 0.3791\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3550 - val_loss: 0.3788\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3531 - val_loss: 0.3777\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.3552 - val_loss: 0.3774\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.3448 - val_loss: 0.3777\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3678 - val_loss: 0.3761\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3760\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3694 - val_loss: 0.3755\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.3591 - val_loss: 0.3743\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3638 - val_loss: 0.3745\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3566 - val_loss: 0.3731\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3583 - val_loss: 0.3730\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.3417 - val_loss: 0.3727\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.3621 - val_loss: 0.3725\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3569 - val_loss: 0.3717\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3615 - val_loss: 0.3708\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3562 - val_loss: 0.3709\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3499 - val_loss: 0.3699\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.3447 - val_loss: 0.3693\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.3519 - val_loss: 0.3690\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3437 - val_loss: 0.3684\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.3529 - val_loss: 0.3683\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3365 - val_loss: 0.3680\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3390 - val_loss: 0.3674\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3563 - val_loss: 0.3669\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3376 - val_loss: 0.3672\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3501 - val_loss: 0.3660\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3384 - val_loss: 0.3660\n",
      "121/121 [==============================] - 0s 655us/step - loss: 0.3727\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.7744 - val_loss: 1.2957\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 1.0756 - val_loss: 0.8012\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.8005 - val_loss: 0.6780\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.6588 - val_loss: 0.6399\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.6400 - val_loss: 0.6165\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5747 - val_loss: 0.5991\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.6037 - val_loss: 0.5812\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.5776 - val_loss: 0.5673\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5570 - val_loss: 0.5543\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.5234 - val_loss: 0.5417\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.529 - 0s 948us/step - loss: 0.5296 - val_loss: 0.5312\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5158 - val_loss: 0.5213\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.4882 - val_loss: 0.5149\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.4919 - val_loss: 0.5052\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.4787 - val_loss: 0.4981\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4889 - val_loss: 0.4922\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.5021 - val_loss: 0.4860\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4775 - val_loss: 0.4813\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.4839 - val_loss: 0.4765\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.4687 - val_loss: 0.4713\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4553 - val_loss: 0.4668\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.4419 - val_loss: 0.4633\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4250 - val_loss: 0.4617\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.4346 - val_loss: 0.4562\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4467 - val_loss: 0.4536\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.4398 - val_loss: 0.4505\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4394 - val_loss: 0.4478\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.4340 - val_loss: 0.4453\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.4149 - val_loss: 0.4433\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4114 - val_loss: 0.4398\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4286 - val_loss: 0.4379\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4363\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.4119 - val_loss: 0.4342\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4168 - val_loss: 0.4318\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.4152 - val_loss: 0.4301\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.4264 - val_loss: 0.4288\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.4357 - val_loss: 0.4265\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4181 - val_loss: 0.4252\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.4239 - val_loss: 0.4233\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.4233 - val_loss: 0.4224\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.4118 - val_loss: 0.4206\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.4168 - val_loss: 0.4190\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.3862 - val_loss: 0.4176\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4338 - val_loss: 0.4160\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.4097 - val_loss: 0.4145\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.4103 - val_loss: 0.4137\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 960us/step - loss: 0.3940 - val_loss: 0.4124\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.4032 - val_loss: 0.4106\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3928 - val_loss: 0.4101\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.3901 - val_loss: 0.4091\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3903 - val_loss: 0.4076\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3904 - val_loss: 0.4063\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.3999 - val_loss: 0.4053\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3832 - val_loss: 0.4050\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3600 - val_loss: 0.4046\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3961 - val_loss: 0.4028\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3903 - val_loss: 0.4017\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.3912 - val_loss: 0.4007\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3786 - val_loss: 0.4000\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3987 - val_loss: 0.3991\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3951 - val_loss: 0.3979\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3790 - val_loss: 0.3981\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4091 - val_loss: 0.3968\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.3685 - val_loss: 0.3958\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.3948\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.3826 - val_loss: 0.3946\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3636 - val_loss: 0.3934\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3640 - val_loss: 0.3924\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.3783 - val_loss: 0.3915\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.3673 - val_loss: 0.3906\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.3674 - val_loss: 0.3899\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.3901\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3837 - val_loss: 0.3889\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3590 - val_loss: 0.3883\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.3733 - val_loss: 0.3873\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3722 - val_loss: 0.3873\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3694 - val_loss: 0.3862\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3649 - val_loss: 0.3852\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3604 - val_loss: 0.3850\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3824 - val_loss: 0.3840\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3641 - val_loss: 0.3838\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.3838\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3530 - val_loss: 0.3824\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.3816\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3821 - val_loss: 0.3808\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3598 - val_loss: 0.3800\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.3802\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3794\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3795\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.3779\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3779\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.3769\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.3763\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3758\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3660 - val_loss: 0.3750\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.3751\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3465 - val_loss: 0.3745\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3747\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.3734\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3376 - val_loss: 0.3727\n",
      "121/121 [==============================] - 0s 656us/step - loss: 0.3614\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9551 - val_loss: 0.6572\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.6235 - val_loss: 0.5997\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5758 - val_loss: 0.5611\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5591 - val_loss: 0.5269\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.4978\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4995 - val_loss: 0.4650\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4587 - val_loss: 0.4465\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4334 - val_loss: 0.4336\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4230\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.4180\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 0.4140\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.3853 - val_loss: 0.4030\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.4019 - val_loss: 0.4068\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3920 - val_loss: 0.3990\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.3924\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3890 - val_loss: 0.3932\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.3909\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.3903\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.3799 - val_loss: 0.3852\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3805 - val_loss: 0.3834\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3798\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3644 - val_loss: 0.3812\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.3698 - val_loss: 0.3808\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.3779\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.3824 - val_loss: 0.3763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3636 - val_loss: 0.3789\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3640 - val_loss: 0.3756\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3664 - val_loss: 0.3797\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3596 - val_loss: 0.3768\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3658 - val_loss: 0.3699\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3642 - val_loss: 0.3702\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3778 - val_loss: 0.3719\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3687 - val_loss: 0.3658\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3579 - val_loss: 0.3724\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3651 - val_loss: 0.3674\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.3797 - val_loss: 0.3667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3703 - val_loss: 0.3659\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.3593 - val_loss: 0.3717\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3703 - val_loss: 0.3640\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.3625 - val_loss: 0.3707\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3608 - val_loss: 0.3650\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3587 - val_loss: 0.3633\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3460 - val_loss: 0.3634\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.3432 - val_loss: 0.3578\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3651 - val_loss: 0.3638\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3623\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.3623\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.3511 - val_loss: 0.3664\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3580 - val_loss: 0.3628\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3608 - val_loss: 0.3619\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3735 - val_loss: 0.3613\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.3622 - val_loss: 0.3638\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3721 - val_loss: 0.3690\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3478 - val_loss: 0.3600\n",
      "121/121 [==============================] - 0s 609us/step - loss: 0.3553\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7295 - val_loss: 0.6876\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.6311 - val_loss: 0.6180\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.5837 - val_loss: 0.5633\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.5318 - val_loss: 0.5271\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4993 - val_loss: 0.4963\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.4801\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4578 - val_loss: 0.4557\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.4398 - val_loss: 0.4406\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.4090 - val_loss: 0.4262\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.4168 - val_loss: 0.4229\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4127 - val_loss: 0.4130\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3843 - val_loss: 0.4048\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3745 - val_loss: 0.4039\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3801 - val_loss: 0.4038\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3635 - val_loss: 0.3948\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3703 - val_loss: 0.4021\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.3835 - val_loss: 0.3888\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.3594 - val_loss: 0.3882\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3811 - val_loss: 0.3866\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.3606 - val_loss: 0.3840\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3617 - val_loss: 0.3855\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3584 - val_loss: 0.3798\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3790 - val_loss: 0.3799\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3701 - val_loss: 0.3829\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3501 - val_loss: 0.3803\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.3814 - val_loss: 0.3778\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3719 - val_loss: 0.3819\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3739\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.3596 - val_loss: 0.3718\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3681 - val_loss: 0.3739\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3426 - val_loss: 0.3720\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3603 - val_loss: 0.3755\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3605 - val_loss: 0.3725\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3568 - val_loss: 0.3684\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3425 - val_loss: 0.3671\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3531 - val_loss: 0.3745\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3369 - val_loss: 0.3680\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.3324 - val_loss: 0.3683\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3469 - val_loss: 0.3660\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.3430 - val_loss: 0.3689\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.3589 - val_loss: 0.3685\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3660\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.3497 - val_loss: 0.3641\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.3530 - val_loss: 0.3637\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3435 - val_loss: 0.3622\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3347 - val_loss: 0.3683\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3544 - val_loss: 0.3599\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3342 - val_loss: 0.3603\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.3442 - val_loss: 0.3648\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 828us/step - loss: 0.3444 - val_loss: 0.3623\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3448 - val_loss: 0.3583\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3339 - val_loss: 0.3583\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3462 - val_loss: 0.3645\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3469 - val_loss: 0.3660\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.3530 - val_loss: 0.3630\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3562 - val_loss: 0.3618\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.3631\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3391 - val_loss: 0.3591\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.3387 - val_loss: 0.3584\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.3772\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3265 - val_loss: 0.3649\n",
      "121/121 [==============================] - 0s 615us/step - loss: 0.3906\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3415 - val_loss: 0.6350\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.6194 - val_loss: 0.5725\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5556 - val_loss: 0.5423\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.5359 - val_loss: 0.5018\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4910 - val_loss: 0.4842\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4802 - val_loss: 0.4682\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4634 - val_loss: 0.4608\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.4610 - val_loss: 0.4483\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.4636 - val_loss: 0.4450\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.4537 - val_loss: 0.4343\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.4374\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4224 - val_loss: 0.4230\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.4227 - val_loss: 0.4291\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4386 - val_loss: 0.4194\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.4056 - val_loss: 0.4202\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.4128 - val_loss: 0.4090\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.4001 - val_loss: 0.4041\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.4060 - val_loss: 0.4019\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3869 - val_loss: 0.4029\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.4034 - val_loss: 0.3977\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3646 - val_loss: 0.3971\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3829 - val_loss: 0.3926\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3821 - val_loss: 0.3895\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3914 - val_loss: 0.3886\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3843 - val_loss: 0.3900\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3780 - val_loss: 0.3835\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3735 - val_loss: 0.3796\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3452 - val_loss: 0.3848\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3664 - val_loss: 0.3822\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3708 - val_loss: 0.3778\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3790 - val_loss: 0.3763\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3799 - val_loss: 0.3796\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3779 - val_loss: 0.3761\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3522 - val_loss: 0.3798\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.3616 - val_loss: 0.3770\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3652 - val_loss: 0.3709\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3714 - val_loss: 0.3674\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3634 - val_loss: 0.3701\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3595 - val_loss: 0.3701\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.3647 - val_loss: 0.3632\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.3704\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3518 - val_loss: 0.3792\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3417 - val_loss: 0.3650\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3411 - val_loss: 0.3612\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3576 - val_loss: 0.3612\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3511 - val_loss: 0.3568\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3522 - val_loss: 0.3670\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.3547\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3543 - val_loss: 0.3578\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3297 - val_loss: 0.3741\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3427 - val_loss: 0.3600\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.3511 - val_loss: 0.3691\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3497 - val_loss: 0.3643\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.3388 - val_loss: 0.3642\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3617 - val_loss: 0.3528\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.3238 - val_loss: 0.3605\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3315 - val_loss: 0.3556\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3293 - val_loss: 0.3711\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3241 - val_loss: 0.3549\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3462 - val_loss: 0.3576\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.3272 - val_loss: 0.3578\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3441 - val_loss: 0.3510\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3345 - val_loss: 0.3593\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3155 - val_loss: 0.3567\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.3497 - val_loss: 0.3516\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3442 - val_loss: 0.3539\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 850us/step - loss: 0.3506 - val_loss: 0.3594\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3496 - val_loss: 0.3535\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.3509\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3418 - val_loss: 0.3540\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3372 - val_loss: 0.3495\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3391 - val_loss: 0.3539\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3387 - val_loss: 0.3481\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3513 - val_loss: 0.3607\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3338 - val_loss: 0.3544\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.3494\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.3507\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.3586\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3414 - val_loss: 0.3589\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3551 - val_loss: 0.3541\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.3308 - val_loss: 0.3563\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3413 - val_loss: 0.3534\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.3328 - val_loss: 0.3520\n",
      "121/121 [==============================] - 0s 613us/step - loss: 0.3388\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6908 - val_loss: 0.6056\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.5362 - val_loss: 0.4865\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4851 - val_loss: 0.4527\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.4300 - val_loss: 0.4281\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.4211 - val_loss: 0.4167\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4224 - val_loss: 0.4066\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3872 - val_loss: 0.4038\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.3899 - val_loss: 0.4032\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.3947 - val_loss: 0.3906\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3900 - val_loss: 0.3979\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3792 - val_loss: 0.3857\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3693 - val_loss: 0.3834\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.3762 - val_loss: 0.3770\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3592 - val_loss: 0.3812\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.3734 - val_loss: 0.3702\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.3585 - val_loss: 0.3681\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.3571 - val_loss: 0.3672\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3418 - val_loss: 0.3714\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3589 - val_loss: 0.3620\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.3409 - val_loss: 0.3585\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3475 - val_loss: 0.3620\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3487 - val_loss: 0.3551\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.3340 - val_loss: 0.3559\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3302 - val_loss: 0.3524\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3452 - val_loss: 0.3544\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3399 - val_loss: 0.3653\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3282 - val_loss: 0.3498\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3212 - val_loss: 0.3461\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3478 - val_loss: 0.3469\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3243 - val_loss: 0.3464\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3222 - val_loss: 0.3404\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3207 - val_loss: 0.3446\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3123 - val_loss: 0.3559\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3643 - val_loss: 0.3399\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3323 - val_loss: 0.3397\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3167 - val_loss: 0.3404\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.3289 - val_loss: 0.3334\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.3089 - val_loss: 0.3267\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.3161 - val_loss: 0.3414\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3116 - val_loss: 0.3293\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.2993 - val_loss: 0.3268\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.2961 - val_loss: 0.3302\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3112 - val_loss: 0.3248\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.2964 - val_loss: 0.3271\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3179 - val_loss: 0.3269\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.2961 - val_loss: 0.3216\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3215 - val_loss: 0.3170\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.3157 - val_loss: 0.3299\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3079 - val_loss: 0.3234\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3079 - val_loss: 0.3210\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.2983 - val_loss: 0.3196\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.2937 - val_loss: 0.3215\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.2987 - val_loss: 0.3213\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.2903 - val_loss: 0.3155\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.2871 - val_loss: 0.3147\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.2882 - val_loss: 0.3112\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.2802 - val_loss: 0.3098\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.2970 - val_loss: 0.3137\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.2902 - val_loss: 0.3172\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.2999 - val_loss: 0.3203\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.2954 - val_loss: 0.3079\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 889us/step - loss: 0.2773 - val_loss: 0.3136\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.2815 - val_loss: 0.3088\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.2824 - val_loss: 0.3129\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2821 - val_loss: 0.3101\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.3067\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.2830 - val_loss: 0.3132\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.2784 - val_loss: 0.3112\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.2791 - val_loss: 0.3061\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.2676 - val_loss: 0.3036\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.2824 - val_loss: 0.3051\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.2691 - val_loss: 0.3072\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.2766 - val_loss: 0.3065\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.2808 - val_loss: 0.3075\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.2674 - val_loss: 0.3105\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.2750 - val_loss: 0.3109\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.2727 - val_loss: 0.3111\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.2746 - val_loss: 0.3139\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2778 - val_loss: 0.3022\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.2657 - val_loss: 0.3074\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.2731 - val_loss: 0.3081\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.2688 - val_loss: 0.3018\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.2786 - val_loss: 0.3031\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.2781 - val_loss: 0.2999\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.2731 - val_loss: 0.3029\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.2793 - val_loss: 0.3027\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.2573 - val_loss: 0.3077\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.2679 - val_loss: 0.3125\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.2779 - val_loss: 0.3040\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.2695 - val_loss: 0.3100\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.2638 - val_loss: 0.3036\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.2711 - val_loss: 0.3036\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.2775 - val_loss: 0.2994\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.2695 - val_loss: 0.3003\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.2678 - val_loss: 0.2968\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.2697 - val_loss: 0.2978\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.2736 - val_loss: 0.3074\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.2728 - val_loss: 0.2990\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.2604 - val_loss: 0.3013\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.2731 - val_loss: 0.3104\n",
      "121/121 [==============================] - 0s 596us/step - loss: 0.3080\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4480 - val_loss: 0.6263\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5705 - val_loss: 0.5268\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4816 - val_loss: 0.4738\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.4359 - val_loss: 0.4494\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.4394 - val_loss: 0.4271\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.4217\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.4093\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.4025\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.3927\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.3906\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3672 - val_loss: 0.3824\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3679 - val_loss: 0.3794\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3609 - val_loss: 0.3741\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.3482 - val_loss: 0.3787\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3500 - val_loss: 0.3671\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3563 - val_loss: 0.3662\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.3625\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.3385 - val_loss: 0.3673\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3427 - val_loss: 0.3621\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3377 - val_loss: 0.3602\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3239 - val_loss: 0.3614\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3506 - val_loss: 0.3549\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3216 - val_loss: 0.3561\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3348 - val_loss: 0.3518\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.3395 - val_loss: 0.3523\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.3321 - val_loss: 0.3495\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3093 - val_loss: 0.3493\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3131 - val_loss: 0.3476\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3400 - val_loss: 0.3488\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.3257 - val_loss: 0.3474\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3168 - val_loss: 0.3390\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.3100 - val_loss: 0.3439\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3192 - val_loss: 0.3469\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.2986 - val_loss: 0.3396\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3139 - val_loss: 0.3400\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3019 - val_loss: 0.3440\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3126 - val_loss: 0.3371\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.3121 - val_loss: 0.3356\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.2997 - val_loss: 0.3353\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 954us/step - loss: 0.3065 - val_loss: 0.3279\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.2943 - val_loss: 0.3320\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.2914 - val_loss: 0.3300\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3087 - val_loss: 0.3281\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.2912 - val_loss: 0.3263\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.2957 - val_loss: 0.3337\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3057 - val_loss: 0.3247\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.2784 - val_loss: 0.3222\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.2896 - val_loss: 0.3268\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.2850 - val_loss: 0.3227\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.2908 - val_loss: 0.3320\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.2891 - val_loss: 0.3195\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.2950 - val_loss: 0.3164\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.2730 - val_loss: 0.3324\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.2882 - val_loss: 0.3183\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.3041 - val_loss: 0.3164\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.2870 - val_loss: 0.3167\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.2938 - val_loss: 0.3141\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.2744 - val_loss: 0.3172\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.2801 - val_loss: 0.3135\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.2802 - val_loss: 0.3175\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.2935 - val_loss: 0.3198\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.2754 - val_loss: 0.3189\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.2594 - val_loss: 0.3169\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.2703 - val_loss: 0.3125\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.2765 - val_loss: 0.3152\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.2779 - val_loss: 0.3090\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 0.3181\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2664 - val_loss: 0.3080\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.2780 - val_loss: 0.3095\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.2785 - val_loss: 0.3141\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.2818 - val_loss: 0.3084\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.2855 - val_loss: 0.3064\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.2727 - val_loss: 0.3118\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.2590 - val_loss: 0.3069\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.2703 - val_loss: 0.3067\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.2728 - val_loss: 0.3099\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.2768 - val_loss: 0.3130\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.2796 - val_loss: 0.3142\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.2677 - val_loss: 0.3066\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.2740 - val_loss: 0.3067\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.2747 - val_loss: 0.3044\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.2729 - val_loss: 0.3039\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.2568 - val_loss: 0.3047\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.2678 - val_loss: 0.3013\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.2757 - val_loss: 0.3178\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.2763 - val_loss: 0.3045\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.2613 - val_loss: 0.3012\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.2614 - val_loss: 0.3098\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.2618 - val_loss: 0.3082\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.2671 - val_loss: 0.3049\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.2740 - val_loss: 0.3400\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2745 - val_loss: 0.3130\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2676 - val_loss: 0.3018\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2679 - val_loss: 0.3065\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.2661 - val_loss: 0.3016\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2745 - val_loss: 0.3075\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.2607 - val_loss: 0.3038\n",
      "121/121 [==============================] - 0s 665us/step - loss: 0.3101\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8337 - val_loss: 0.6511\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5737 - val_loss: 0.5054\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4623 - val_loss: 0.4598\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4403 - val_loss: 0.4427\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.4205\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4048 - val_loss: 0.4134\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.4230\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.3986\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3711 - val_loss: 0.3970\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.4006\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.3872\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.3845\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3767 - val_loss: 0.3796\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3803\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3746\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.3747\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.3734\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3712\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.3689\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.3692\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.3663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.3615\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.3617\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3391 - val_loss: 0.3584\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3558\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 0.3614\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.3553\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.3582\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.3545\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.3530\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3489\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.3552\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3456\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.3446\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.3435\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.3459\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3545\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.3407\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.3397\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.3186 - val_loss: 0.3382\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3367\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.2996 - val_loss: 0.3389\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3115 - val_loss: 0.3379\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.3364\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.3382\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.3387\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3392\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3275\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2891 - val_loss: 0.3336\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3066 - val_loss: 0.3298\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.3284\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2948 - val_loss: 0.3314\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2947 - val_loss: 0.3264\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3134 - val_loss: 0.3300\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 0.3279\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.3322\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3058 - val_loss: 0.3263\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2980 - val_loss: 0.3238\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3068 - val_loss: 0.3279\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.3407\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.3205\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 0.3228\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2859 - val_loss: 0.3264\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.3178\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2915 - val_loss: 0.3253\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.2857 - val_loss: 0.3187\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2922 - val_loss: 0.3170\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 0.3180\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.3157\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.2880 - val_loss: 0.3146\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2893 - val_loss: 0.3196\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2907 - val_loss: 0.3195\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.2802 - val_loss: 0.3171\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2980 - val_loss: 0.3164\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.3194\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2726 - val_loss: 0.3142\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3010 - val_loss: 0.3151\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2835 - val_loss: 0.3151\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2701 - val_loss: 0.3254\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2623 - val_loss: 0.3149\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.3206\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2733 - val_loss: 0.3167\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3004 - val_loss: 0.3121\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 0.3195\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2736 - val_loss: 0.3106\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2681 - val_loss: 0.3151\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 0.3110\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2769 - val_loss: 0.3160\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 0.3145\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 0.3151\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2899 - val_loss: 0.3179\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2732 - val_loss: 0.3166\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.2800 - val_loss: 0.3092\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.2767 - val_loss: 0.3122\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2771 - val_loss: 0.3161\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2703 - val_loss: 0.3090\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2699 - val_loss: 0.3101\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.2873 - val_loss: 0.3141\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2746 - val_loss: 0.3079\n",
      "121/121 [==============================] - 0s 590us/step - loss: 0.3031\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [-4.01807606e-01 -3.58172725e-01             nan -5.56665436e+24\n",
      "             nan -3.12869936e-01 -3.27100774e-01 -3.66168082e-01\n",
      " -3.61552586e-01 -3.07083527e-01]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 1.5299 - val_loss: 0.5831\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.5412 - val_loss: 0.4815\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 973us/step - loss: 0.4557 - val_loss: 0.4525\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4363 - val_loss: 0.4371\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.4039 - val_loss: 0.4185\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.3961 - val_loss: 0.4042\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 786us/step - loss: 0.3960 - val_loss: 0.3929\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3675 - val_loss: 0.3901\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 780us/step - loss: 0.3719 - val_loss: 0.3811\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.3806 - val_loss: 0.3880\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.3824 - val_loss: 0.3724\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 796us/step - loss: 0.3397 - val_loss: 0.3726\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.3481 - val_loss: 0.3640\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 783us/step - loss: 0.3421 - val_loss: 0.3610\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 835us/step - loss: 0.3588 - val_loss: 0.3593\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.3485 - val_loss: 0.3584\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 791us/step - loss: 0.3426 - val_loss: 0.3530\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3432 - val_loss: 0.3593\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.3376 - val_loss: 0.3500\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 796us/step - loss: 0.3615 - val_loss: 0.3433\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.3293 - val_loss: 0.3460\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.3419 - val_loss: 0.3479\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 811us/step - loss: 0.3182 - val_loss: 0.3382\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 907us/step - loss: 0.3258 - val_loss: 0.3368\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.3170 - val_loss: 0.3634\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.3277 - val_loss: 0.3384\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 799us/step - loss: 0.3171 - val_loss: 0.3333\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.3031 - val_loss: 0.3334\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.3039 - val_loss: 0.3346\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.3195 - val_loss: 0.3344\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 799us/step - loss: 0.3119 - val_loss: 0.3211\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.2986 - val_loss: 0.3246\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.3075 - val_loss: 0.3267\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 827us/step - loss: 0.3122 - val_loss: 0.3330\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.3094 - val_loss: 0.3215\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.3083 - val_loss: 0.3263\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 766us/step - loss: 0.2997 - val_loss: 0.3211\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 795us/step - loss: 0.3128 - val_loss: 0.3134\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.2812 - val_loss: 0.3142\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.2968 - val_loss: 0.3170\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.2839 - val_loss: 0.3199\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 849us/step - loss: 0.2961 - val_loss: 0.3220\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 802us/step - loss: 0.2971 - val_loss: 0.3130\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.2815 - val_loss: 0.3132\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.2910 - val_loss: 0.3186\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.2977 - val_loss: 0.3085\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.2858 - val_loss: 0.3141\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 816us/step - loss: 0.2771 - val_loss: 0.3100\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.2856 - val_loss: 0.3105\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.2770 - val_loss: 0.3032\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 810us/step - loss: 0.2902 - val_loss: 0.3086\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 852us/step - loss: 0.2845 - val_loss: 0.3057\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 780us/step - loss: 0.2909 - val_loss: 0.3122\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.2712 - val_loss: 0.3023\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.2708 - val_loss: 0.3026\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.2816 - val_loss: 0.3257\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.2898 - val_loss: 0.3028\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.2892 - val_loss: 0.3381\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 835us/step - loss: 0.2835 - val_loss: 0.3058\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 765us/step - loss: 0.2725 - val_loss: 0.3003\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 810us/step - loss: 0.2830 - val_loss: 0.3104\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.2772 - val_loss: 0.3187\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.2790 - val_loss: 0.3133\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.2809 - val_loss: 0.3042\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 801us/step - loss: 0.2816 - val_loss: 0.3003\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.2758 - val_loss: 0.3019\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.2956 - val_loss: 0.3016\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.2765 - val_loss: 0.3012\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.2822 - val_loss: 0.3005\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.2838 - val_loss: 0.3061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x000001F98C56CB48>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001F990B21308>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv=RandomizedSearchCV(keras_reg,param_distributions=param_distribs,n_iter=10,cv=3)\n",
    "rnd_search_cv.fit(X_train,y_train,epochs=100,validation_data=(X_valid,y_valid),callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6d8c09a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.006469484918566646, 'n_hidden': 2, 'n_neurons': 62}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "409b4cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.307083527247111"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aab1da23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "332d7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(filepath='./best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dabac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
