{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6456741b",
   "metadata": {},
   "source": [
    "# 像numpy一样使用Tensorflow\n",
    "## 张量和操作\n",
    "- 可以使用tf.constant1()操作创建张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b0ece8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 两行三列浮点数矩阵的张量\n",
    "import tensorflow as tf\n",
    "tf.constant([[1.,2.,3.],[4.,5.,6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed2cc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标量\n",
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c215ffe6",
   "metadata": {},
   "source": [
    "就像ndarray一样tf.Tensor具有形状和数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b0612c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=tf.constant([[1.,2.,3.],[4.,5.,6.]])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9eb24c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db0520f",
   "metadata": {},
   "source": [
    "索引的工作方式非常像numpy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23817f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6346ca81",
   "metadata": {},
   "source": [
    "最重要的是可以使用各种张量操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e45d720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9017d30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b3d658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t@tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcaf6c9",
   "metadata": {},
   "source": [
    "## 张量和numpy\n",
    "张量可以与NumPy配合使用:你可以用numpy数组创建张量，反之亦然。你甚至可以将Tensorflow操作应用于Numpy数组，将numpy操作应用于张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c8d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.array([2.,4.,5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab4551d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e097b470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7df36b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9bb063b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d632b4",
   "metadata": {},
   "source": [
    "注意默认情况下numpy使用64位精度，而TensorFlow使用32位精度。因此当你从numpy数组创建张量时，请确保设置dtype=tf.float32。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d410d",
   "metadata": {},
   "source": [
    "## 类型转换\n",
    "Tensorflow不会自动执行任何类型转换，如果你对不兼容类型的张量操作，会引发异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "787418c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行类型转换\n",
    "t2=tf.constant(40.,dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dac333ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(2.0)+tf.cast(t2,tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c303e3",
   "metadata": {},
   "source": [
    "## 变量\n",
    "到目前为止，我们看到的tf.Tensor值是不变的，无法修改它们。我们需要的是题tf.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7c4a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=tf.Variable([[1.,2.,3.],[4.,5.,6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc7f394c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1264c",
   "metadata": {},
   "source": [
    "## 其它数据结构\n",
    "- 稀疏张量 tf.SparseTensor\n",
    "- 张量数组 tf.TensorArray\n",
    "- 不规则张量 tf.RaggedTensor\n",
    "- 字符串张量 tf.string\n",
    "- 集合 tf.sets\n",
    "- 队列 tf.queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2118a393",
   "metadata": {},
   "source": [
    "# 定制模型和训练算法\n",
    "## 自定义损失函数\n",
    "来写一个huber损失函数。![huber loss](./huber.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf122853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此时假设阈值δ为1\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "# where是三元表达式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01deace",
   "metadata": {},
   "source": [
    "应仅使用tf操作。可以在编译的时候使用该损失函数model.compile(loss=huber_fn, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7295de3",
   "metadata": {},
   "source": [
    "## 保存和加载具有自定义组件的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15b145ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "167843f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef5249d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ade192b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer=keras.optimizers.Nadam(), metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c056bdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 13s 2ms/step - loss: 0.9688 - mae: 1.3701 - val_loss: 223.1692 - val_mae: 223.6692\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2114 - mae: 0.5050 - val_loss: 193.3801 - val_mae: 193.8801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20e6fdf3388>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train,epochs=2,validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31e37939",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_with_a_custom_loss.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455cffd1",
   "metadata": {},
   "source": [
    "一般而言，当加载包含自定义对象的模型时，需要将名称映射到对象上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ab787bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('my_model_with_a_custom_loss.h5',custom_objects={'huber_fn':huber_fn})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155b174",
   "metadata": {},
   "source": [
    "我们创建一个可以设定不同阈值的huber损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1861132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold*tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5906043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0),optimizer=keras.optimizers.Nadam(),metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453d858d",
   "metadata": {},
   "source": [
    "不幸的是当你保存模型的时候不会保存阈值。这意味着在加载模型时必须指定阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b089a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 0.2354 - mae: 0.5039 - val_loss: 0.2501 - val_mae: 0.4947\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2213 - mae: 0.4873 - val_loss: 0.2217 - val_mae: 0.4912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20e70838108>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5025e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f43c19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1553048",
   "metadata": {},
   "source": [
    "可以通过创建keras.losses.Loss类的子类，然后实现其get_config()方法来解决此问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a8c6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self,threshold=1.0,**kwargs):\n",
    "        self.threshold=threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self,y_true,y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold*tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config=super().get_config()\n",
    "        return {**base_config,'threshold':self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3b35aa",
   "metadata": {},
   "source": [
    "然后你可以在编译模型时使用此类的任何实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b15cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.0),optimizer=keras.optimizers.Nadam(),metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "645c398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 0.2214 - mae: 0.4932 - val_loss: 0.2070 - val_mae: 0.4734\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2165 - mae: 0.4882 - val_loss: 0.2098 - val_mae: 0.4770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20e70359d48>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dbad9c",
   "metadata": {},
   "source": [
    "当你保存模型的时候阈值会一起保存，当你加载模型的时候只需要将类名映射到函数本身即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ac48cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c6060a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
    "                                custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7f6b73",
   "metadata": {},
   "source": [
    "## 自定义激活函数和正则化约束"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb925b7",
   "metadata": {},
   "source": [
    "自定义激活函数softplus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cd364a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z)+1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b36222e",
   "metadata": {},
   "source": [
    "自定义初始化glorot_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d0a00f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_glorot_initializer(shape,dtype=tf.float32):\n",
    "    stddev=tf.sqrt(2./(shape[0]+shape[1]))\n",
    "    return tf.random.normal(shape,stddev=stddev,dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60774039",
   "metadata": {},
   "source": [
    "自定义l1正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b617f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01*weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8efd206",
   "metadata": {},
   "source": [
    "确保权重为正的自定义约束keras.contraints.nonneg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d834c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights<0.,tf.zeros_like(weights),weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd107983",
   "metadata": {},
   "source": [
    "然后就可以使用这些函数了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd099508",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(30, activation=my_softplus, kernel_initializer=my_glorot_initializer,\n",
    "                           kernel_regularizer=my_l1_regularizer, kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6332608",
   "metadata": {},
   "source": [
    "激活函数将应用于此Dense层的输出，其结果将传递下一层。层的权重将使用初始化程序返回的值进行初始化。在每个训练步骤中，权重将传递给正则化函数以计算正则化损失，并将其添加到主要损失中以得到用于训练的最终损失。最后将在每个训练步骤结束后调用约束函数，并将层的权重替换为约束权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f07b48d",
   "metadata": {},
   "source": [
    "如果函数具有需要与模型一起保存的超参数，你需要继承适当的类。注意你必须要实现call()（损失、层和模型）或者__ call __()（正则化、初始化、约束）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f59525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self,factor):\n",
    "        self.factor=factor\n",
    "    def __call__(self,weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor*weights))\n",
    "    def get_config(self):\n",
    "        return {'factor':self.factor}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6d68c",
   "metadata": {},
   "source": [
    "## 自定义评价指标\n",
    "大多数情况下，定义一个指标函数与定义一个损失函数大致相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cfdabcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Nadam(),loss='mse',metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4325376",
   "metadata": {},
   "source": [
    "训练的每个批次，Keras都会计算该指标并跟踪自轮次开始和以来的均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10e0af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "percision=keras.metrics.Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "800ce01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percision([0,1,1,1,0,1,0,1],[1,1,0,1,0,1,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c84660",
   "metadata": {},
   "source": [
    "前面是标签，后面是预测。正例1中5个有4个被预测正确，所以精确度为80%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1722713",
   "metadata": {},
   "source": [
    "自定义部分不做重点说明。详细见书。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9069eca8",
   "metadata": {},
   "source": [
    "## 自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d6b5ab",
   "metadata": {},
   "source": [
    "首先某些层没有权重，例如keras.layers.Flatten()。要创建一个不带权重的层，最简单的选择就是编写一个函数并将其包装在Lambda层中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf84256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下层对它的输入应用指数函数。\n",
    "exponential_layer=keras.layers.Lambda(lambda x : tf.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd9fef",
   "metadata": {},
   "source": [
    "要创建自定义的有状态层(即具有权重的层),你需要创建keras.layers.Layer类的子类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6b1d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下实现了Dense层的简化版本。\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self,units,activation=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units=units\n",
    "        self.activation=keras.activations.get(activation)\n",
    "    def build(self,batch_input_shape):\n",
    "        self.kernel=self.add_weight(name='kernel',shape=[batch_input_shape[-1],self.units],initializer='glorot_normal')\n",
    "        self.bias=self.add_weight(name='bias',shape=[self.units],initializer='zeros')\n",
    "        super().build(batch_input_shape) # 必须放在最后\n",
    "    def call(self,X):\n",
    "        return self.activationa(X@self.kernel+self.bias)\n",
    "    def compute_output_shape(self,batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1]+[self.units])\n",
    "    def get_config(self):\n",
    "        base_config=super().get_config()\n",
    "        return {**base_config,'units':self.units,'activation':keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb57c18",
   "metadata": {},
   "source": [
    "build(self, input_shape)：此方法可用于创建依赖于输入形状的权重，使用 add_weight()。 __ call __() 将通过调用 build() 自动构建层（如果尚未构建）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8b8dca",
   "metadata": {},
   "source": [
    "每一个方法的具体解释见书。不看也能理解。通常可以省略compute_output_shape()方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9131cb17",
   "metadata": {},
   "source": [
    "要创建一个具有多个输入的层，call()方法的参数应该包含所有输入的元组，同样，compute_output_shape()方法的参数应该是一个包含每个输入批处理形状的元组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20588558",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self,X):\n",
    "        X1,X2=X\n",
    "        return [X1+X2,X1*X2,X1/X2]\n",
    "    def compute_output_shape(self,batch_input_shape):\n",
    "        b1,b2=batch_input_shape\n",
    "        return [b1,b1,b1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d9e2f",
   "metadata": {},
   "source": [
    "如果你的层在训练期间和测试期间需要有不同的行为，则必须将训练参数添加到call()方法并使用此参数来决定要做什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbaa8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self,stddev,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev=stddev\n",
    "    def call(self,X,training=None):\n",
    "        if training:\n",
    "            noise=tf.random.normal(tf.shape(X),stddev=self.stddev)\n",
    "            return X+noise\n",
    "        else:\n",
    "            return X\n",
    "    def compute_output_shape(self,batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e572a",
   "metadata": {},
   "source": [
    "## 自定义模型\n",
    "![custom model](./custom_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fdb0d7",
   "metadata": {},
   "source": [
    "**要实现此模型，首先最好要创建一个ResidualBlock层，因为我们要创建几个相同的块。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a364918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self,n_layers,n_neurons,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden=[keras.layers.Dense(n_neurons,activation='elu',kernel_initializer='he_normal') for _ in range(n_layers)]\n",
    "    def call(self,inputs):\n",
    "        Z=inputs\n",
    "        for layer in self.hidden:\n",
    "            Z=layer(Z) # 输入按层传递\n",
    "        return inputs+Z # 拟合图中输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68fc85f",
   "metadata": {},
   "source": [
    "这层比较特殊，因为包含其它的层。这会由keras透明处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb675b",
   "metadata": {},
   "source": [
    "接下来我们用model子类api来实现该模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "779ed28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.Model):\n",
    "    def __init__(self,output_dim,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1=keras.layers.Dense(30,activation='elu',kernel_initializer='he_normal')\n",
    "        self.block1=ResidualBlock(2,30)\n",
    "        self.block2=ResidualBlock(2,30)\n",
    "        self.out=keras.layers.Dense(output_dim)\n",
    "    def call(self,inputs):\n",
    "        Z=self.hidden1(inputs)\n",
    "        for _ in range(1+3):\n",
    "            Z=self.block1(Z) # 先走一次，再回来走三次\n",
    "        Z=self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a906d",
   "metadata": {},
   "source": [
    "如果你还希望能够使用save()方法保存模型和load_model()加载模型，则必须在两个ResidualBlock类和ResidualRegressor类中实现get_config()方法。（就像以前一样）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c502829",
   "metadata": {},
   "source": [
    "## 基于模型内部的损失和指标\n",
    "例如我们构建一个自定义回归MLP模型，该模型由5个隐藏层和一个输出层的堆栈组成。此自定义模型还将在上部隐藏层的顶部有辅助输出。与该辅助输出相关的损失称之为重建损失。详见17章。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0148940",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self,output_dim,**kwargs):\n",
    "        super().__init___(**kwargs)\n",
    "        self.hidden=[keras.layers.Dense(30,activation='selu',kernel_initializer='lecun_normal') for _ in range(5)]\n",
    "        self.out=keras.layers.Dense(output_dim)\n",
    "    def build(self,batch_input_shape):\n",
    "        n_inputs=batch_input_shape[-1]\n",
    "        self.reconstruct=keras.layers.Dense(n_inputs)\n",
    "        super().build(batch_input_shape)\n",
    "    def call(self,inputs):\n",
    "        Z=inputs\n",
    "        for layer in self.hidden:\n",
    "            Z=layer(Z)\n",
    "        reconstruction=self.reconstruct(Z)\n",
    "        recon_loss=tf.reduce_mean(tf.square(reconstruction-inputs))\n",
    "        self.add_loss(0.05*recon_loss)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda3be1",
   "metadata": {},
   "source": [
    "- 构造函数创建具有5个隐藏层和一个密集输出层的DNN\n",
    "- build()方法这是你定义权重的地方。在这里创建一个密集层，该层用于重建模型的输入。\n",
    "- call()方法处理所有5个隐藏层的输入，然后将结果传递到重建层，从而产生重构。\n",
    "- 然后call()方法计算重建损失，并使用add_loss()方法将其添加到模型的损失列表中。\n",
    "- 最后call()方法将隐藏层的输出传递到输出层将其输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc40485",
   "metadata": {},
   "source": [
    "## 使用自动微分计算梯度\n",
    "让我们考虑一个简单的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "050758fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1,w2):\n",
    "    return 3*w1**2+2*w1*w2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83d9b98",
   "metadata": {},
   "source": [
    "该函数对w1的偏导数是6 * w1+2 * w2，对w2的偏导数是2 * w1。但是对于神经网络手工分析找到偏导数几乎是不可能完成的任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99961984",
   "metadata": {},
   "source": [
    "一种方案是通过在调整相应的参数时测量函数输出的变化来计算每个偏导数的近似值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06984fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1,w2=5,3\n",
    "eps=1e-6\n",
    "(f(w1+eps,w2)-f(w1,w2))/eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d52770a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1,w2+eps)-f(w1,w2))/eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72fea13",
   "metadata": {},
   "source": [
    "看起来不错，但这只是一个近似值。重要的是每个参数至少要调用一次f()，这种方法对于大型神经网络来说很棘手。因此，我们应该使用自动微分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5384b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1,w2=tf.Variable(5.),tf.Variable(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8791bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z=f(w1,w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c3ef2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients=tape.gradient(z,[w1,w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3225ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49fef9c",
   "metadata": {},
   "source": [
    "我们首先定义两个变量w1和w2，然后创建一个tf.GradientTape上下文,该上下文将自动记录涉及变量的每个操作。最后我们要求该tape针对两个变量w1和w2计算结果z的梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d8e4f",
   "metadata": {},
   "source": [
    "调用tape的gradient()方法后，tape会立即被自动擦除，因此如果你尝试两次调用gradient()，则会出现异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72b76ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z=f(w1,w2)\n",
    "    \n",
    "gradients=tape.gradient(z,w1)\n",
    "# gradients=tape.gradient(z,w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2430803",
   "metadata": {},
   "source": [
    "如果你需要多次调用gradient()方法后，tape必须具有持久性，并在每次使用完该tape后将其删除以释放资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ece8e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z=f(w1,w2)\n",
    "\n",
    "gradients=tape.gradient(z,w1)\n",
    "gradients=tape.gradient(z,w2)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b26b5",
   "metadata": {},
   "source": [
    "后面部分略，详见书。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36820fdf",
   "metadata": {},
   "source": [
    "## 自定义训练循环\n",
    "**一般情况下，不要自定义训练循环，使用默认的fit()方法。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57911473",
   "metadata": {},
   "source": [
    "首先我们建立一个简单的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4005257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([keras.layers.Dense(30, activation='elu', kernel_initializer='he_normal',\n",
    "                                kernel_regularizer=l2_reg), keras.layers.Dense(1, kernel_regularizer=l2_reg)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5407ff",
   "metadata": {},
   "source": [
    "接下来我们创建一个小函数,从训练集中随机采样一批实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df64d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X,y,batch_size=32):\n",
    "    idx=np.random.randint(len(X),size=batch_size)\n",
    "    return X[idx],y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53ed9d",
   "metadata": {},
   "source": [
    "让我们定义一个函数来显示训练状态，包括步数和总步数，从轮次开始以来的平均损失，和其它指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "466478d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration,total,loss,metrics=None):\n",
    "    metrics=' - '.join([\"{}:{:.4f}\".format(m.name,m.result()) for m in [loss]+(metrics or [])])\n",
    "    end='' if iteration<total else '\\n'\n",
    "    print('\\r{}/{} - '.format(iteration,total)+metrics,end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d5d96",
   "metadata": {},
   "source": [
    "后面也省略。详细见书。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7b455",
   "metadata": {},
   "source": [
    "# TensorFlow函数和图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c8e1ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bda746e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9a947e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638b5c6",
   "metadata": {},
   "source": [
    "现在我们要tf.function()将此python函数转换成Tensorflow函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9d8c3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_cube=tf.function(func=cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3d68dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x20e78b10a08>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b097f3",
   "metadata": {},
   "source": [
    "然后就可以像使用python函数一样使用此tf函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb7a3171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc84421f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe6c1d",
   "metadata": {},
   "source": [
    "在后台，tf.function()分析了cube()函数执行的计算，并生成等效的计算图。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e5463",
   "metadata": {},
   "source": [
    "另外我们也可以用tf.function作为修饰器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "615e503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9da50",
   "metadata": {},
   "source": [
    "也可以用TF函数的python_function属性使用原python函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "06f60842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3936ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
